id,authorId,author,authorUrl,authorType,authorHeadline,title,type,url,excerpt,voteupCount,commentCount,zfavCount,createdTime,updatedTime,content
664346177,354a091a04e0c20269578c0064f8d2a4,AI技能研究所,https://api.zhihu.com/people/354a091a04e0c20269578c0064f8d2a4,people,程序员的进阶之旅,什么是<em>人工智能</em>？如何学习人工智能？,article,https://api.zhihu.com/articles/664346177,作为一个 985 本硕计算机的<em>人工智能</em>经验开发者来谈谈我对人工智能的理解，全文 3000 余字都是干货，建议收藏、点赞后观看。一句话，<em>人工智能</em>，是机器能够具有与人类思维相关的认知功能的能力。 作为一个长期在<em>人工智能</em>行业挣扎的经验者，有必要来回答这个问题，给新入行、想入行的同学一些经验分享,275,5,0,1698742852,1698743073,<p data-pid="8TrX6zJu"><b>作为一个 985 本硕计算机的人工智能经验开发者来谈谈我对人工智能的理解，全文 3000 余字都是干货，建议收藏、点赞后观看。</b></p><h3><b>一句话，人工智能，是机器能够具有与人类思维相关的认知功能的能力。</b></h3><p data-pid="1l-OCghp"><b>作为一个长期在人工智能行业挣扎的经验者，有必要来回答这个问题，给新入行、想入行的同学一些经验分享，本片内容涉及广、涵盖多，建议收藏、点赞、关注三连后慢慢食用</b></p><p data-pid="CNKcKh2i">人类和机器的渊源，缠绵古今。如果没有借助、发现、发明、使用机器，我们人类这个物种注定不会走的太远。从近代来说，<span class="nolink">农业机械化</span>、汽车、高铁、建筑设备等等，都是机器。这些机器长期以来帮助我们改进我们的生活状态和品质。</p><p data-pid="8bw-0YKn">另一方面，人类是矛盾的，即倾向于使用更便捷的机器，又害怕的担心机器的智能发展飞快。二十世纪的理论家，如<span class="nolink">计算机科学家</span>和数学家<span class="nolink">艾伦·图灵</span>，设想了一个机器可以比人类更快地<span class="nolink">执行功能</span>的未来，就是<span class="nolink">人工智能时代</span>。</p><p data-pid="dMvOD7kb">自计算机在 20 世纪 70 年代开始普及以来，计算机的功能越来越复杂，计算能力越来越强，由此展开对人工智能这一愿景的实现。</p><p data-pid="CQVdi-y4"><b>人工智能是机器执行与人类思维相关的认知功能的能力，例如感知、推理、学习、与环境交互、解决问题，甚至发挥创造力的未来世界的愿景。</b></p><h2>目前的人工智能是什么？</h2><p data-pid="byi-MLVO">人工智能 (AI) 是计算机科学的一个广泛分支，涉及构建能够执行通常需要<span class="nolink">人类智能</span>的任务的智能机器。虽然人工智能是一门具有多种方法的跨学科科学，但尤其是机器学习和深度学习的进步正在为科技行业的几乎每个领域带来范式转变。</p><ul><li data-pid="iomcggU3"><b>将人工智能称之为机器可以具有人类思维相关认知能力的愿景</b></li><li data-pid="JaWeQge3">目前解决的方式是通过机器学习的方法来逼近人工智能这一个愿景</li><li data-pid="MlAZujkf">其中深度学习是机器学习中目前效果较好且最火热的一个技术分支</li></ul><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-e53e8c38dac2ba80e1d7b0fecaa7caec_b.jpg" data-caption="" data-size="normal" class="content_image" data-original-token="v2-e53e8c38dac2ba80e1d7b0fecaa7caec"/></figure><p data-pid="9jIbbEs-">让我们看一个人工智能驱动产品的例子——Amazon Echo，Amazon Echo 是一款使用亚马逊开发的<span class="nolink">虚拟助理</span>人工智能技术 Alexa 的<span class="nolink">智能音箱</span>。Amazon Alexa 能够进行语音交互、播放音乐、设置闹钟、播放有声读物以及提供新闻、天气、体育和交通报告等实时信息。<br/> </p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-ef259fa0f5337c381ba1baf599c1d1d2_b.jpg" data-caption="" data-size="normal" class="content_image" data-original-token="v2-ef259fa0f5337c381ba1baf599c1d1d2"/></figure><h2>人工智能的等级</h2><p data-pid="ArwCflEF">目前就人工智能的发展趋势来看，可以把人工智能划分为三个层级，<b>弱人工智能（ANI），<span class="nolink">通用人工智能</span>（AGI）和超级人工智能（ASI）</b>三类。</p><p data-pid="Er9pC193"><b>弱人工智能（ANI）：</b>是迄今为止成功完成的人工智能技术。 ANI(Artificial Narrow Intelligence)被设计出来用来执行单个任务并且以目标为导向。 ANI 非常有能力完成其编程要完成的特定任务。 ANI 的一些示<span class="nolink">例是语音</span>助<span class="nolink">手、面部</span>识别或驾驶汽车。</p><p data-pid="q5DnhC1m"><b>通用人工智能（AGI）：</b>是具有通用人工思维的智能机器，机器可以模仿人类的智能和行为，并具有从数据中学习并应用其智能来解决任何问题的能力。<span class="nolink">人工通用情报</span>可以在任何给定情况下以类似于人类的方式思考、理解和行动，目前最火热的 ChatGPT 正属于这个阶段。</p><p data-pid="gc9McL3U"><b>超级人工智能（ASI）：</b>可以变得自我意识并超越人类能力和智能的假想，距离目前这个阶段还很遥远。</p><p data-pid="jeHRUBJ_"><b>说道这里就需要谈一下最近在知乎<span class="nolink">知学堂</span>上的一门课《<span class="nolink">程序员的 AI 大模型进阶</span>之旅</b>》；</p><a data-draft-node="block" data-draft-type="edu-card" data-edu-card-id="1702729766845812736"></a><p data-pid="QUs4n8n9"><b>上面的链接就是公开课的链接，<span class="nolink">完全免费</span>的科普课程。添加课程之后一定一定一定要添加助教小姐姐的微信，可以私聊助教领取今年最火最热的大模型学习资源！</b></p><p data-pid="mfi0kfZw">目前入行人工智能需要从机器学习、深度学习知识点出发，来学习相关技术，才能从事相关人工智能行业。下面简单来说说如何入手这些技术，从而可以达到入行人工智能的程度。</p><h2>什么是机器学习？</h2><p data-pid="qR1QHaMg">机器学习是计算机科学的一门学科，它使用计算机算法和分析来构建可以解决业务问题的<span class="nolink">预测模型</span>。</p><p data-pid="Ed-2Vj0T">根据<span class="nolink">麦肯锡公司</span>的说法，机器学习基于可以从数据中学习的算法，而无需依赖基于规则的编程。</p><p data-pid="X4umApON"><b>「如果计算机程序在 T 中的任务中的性能（按 P 测量）随着经验 E 的提高而提高，则可以说它可以从关于某类任务 T 和性能测量 P 的经验 E 中学习。」</b></p><p data-pid="vP5fmamO">所以你看，机器学习有很多定义。但它到底是如何运作的呢？</p><h2>机器学习如何工作？</h2><p data-pid="6kX2x4mO">机器学习访问大量数据（结构化和非结构化）并从中学习以预测未来。它通过使用多种算法和技术从数据中学习。下图显示了机器如何从数据中学习。</p><p data-pid="cybJ09t2">上面一张图就完全展示了机器学习是如何工作的，如果想要自学机器学习的朋友，可以参考这几篇内容：</p><p class="ztext-empty-paragraph"><br/></p><a href="https://www.zhihu.com/question/27468261/answer/3165416828" data-draft-node="block" data-draft-type="link-card" data-image="https://pic3.zhimg.com/v2-c51b70700d40a993928fe7cfd3cf8712_l.jpg" data-image-width="720" data-image-height="659" class="internal">如何自学机器学习Machine Learning？</a><a href="https://www.zhihu.com/question/504465921/answer/3159529591" data-draft-node="block" data-draft-type="link-card" data-image="https://pic3.zhimg.com/v2-57f6868b901ffc798c7f5ed4c2149396_qhd.jpg" data-image-width="275" data-image-height="183" class="internal">入门机器学习，哪些书籍值得看？</a><h2><br/>机器学习的类型</h2><p data-pid="n6A877yi">机器学习算法主要分为三大类：</p><h3>1. 监督学习</h3><p data-pid="NPvNNSG0">在<b>监督学习</b>中，数据已经被标记，这意味着你知道目标变量。使用这种学习方法，<b>系统可以根据过去的数据预测未来的结果。它要求至少为模型提供输入和输出变量才能对其进行训练。</b></p><p data-pid="CCqGxCGm">下面是监督学习方法的一个例子。该算法是使用狗和猫的标记数据进行训练的。经过训练的模型可以预测新图像是猫还是狗。<br/> </p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-15f873ebbf21a2084aa71dbec30c29c7_b.jpg" data-caption="" data-size="normal" class="content_image" data-original-token="v2-15f873ebbf21a2084aa71dbec30c29c7"/></figure><p data-pid="HmsToZAq"> 监督学习的一些例子包括<b>线性回归、逻辑回归、<a href="https://www.zhihu.com/search?q=%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3172224248%7D" class="internal">支持向量机</a>、朴素贝叶斯和决策树。</b></p><h3>2.无监督学习</h3><p data-pid="Z1lHrlI9"><b>无监督学习算法利用未标记的数据自行从数据中发现模式。</b>该系统能够从提供的输入数据中识别隐藏的特征。一旦数据更具可读性，模式和相似性就会变得更加明显。</p><p data-pid="_X9Vgy9t">下面是一个使用未标记数据训练模型的无监督学习方法的示例。在这种情况下，数据由不同的车辆组成。该模型的目的是对每种车辆进行分类。<br/> </p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-744d62942f6e1086365ba7d7a8857425_b.jpg" data-caption="" data-size="normal" class="content_image" data-original-token="v2-744d62942f6e1086365ba7d7a8857425"/></figure><p data-pid="EvTT2MrY">无监督学习的一些示例包括 k 均值聚类、<span class="nolink">层次聚类</span>和异常检测。</p><h3>3. 强化学习</h3><p data-pid="i6gc4V7U">强化学习的目标是训练智能体在不确定的环境中完成任务。代理从环境中接收观察结果和奖励，并向环境发送操作。奖励衡量行动在完成任务目标方面的成功程度。</p><p data-pid="hIyAfKJ5">下面的示例展示了如何训练机器识别形状。<br/> </p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-d5130cb2a09befd1aaabec84b34f66d9_b.jpg" data-caption="" data-size="normal" class="content_image" data-original-token="v2-d5130cb2a09befd1aaabec84b34f66d9"/></figure><p data-pid="z0ZjOqDR">强化学习算法的示例包括 Q 学习和深度 Q 学习<span class="nolink">神经网络</span></p><h2>什么是深度学习？</h2><p data-pid="O4atfnvV">深度学习是机器学习的一个子集，它处理受人脑结构和功能启发的算法。深度学习算法可以处理大量结构化和<span class="nolink">非结构化数据</span>。深度学习的核心概念在于<span class="nolink">人工神经网络</span>，它使机器能够做出决策。</p><p data-pid="CEEW_gjy"><b>深度学习与机器学习之间的主要区别在于数据呈现给机器的方式。机器学习算法通常需要结构化数据，而深度学习网络则在多层人工神经网络上工作。</b></p><p data-pid="6CVfEMuA">这是一个简单的神经网络的样子：<br/> </p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-603b6cc91ce0bfc251e844ae7270a312_b.jpg" data-caption="" data-size="normal" class="content_image" data-original-token="v2-603b6cc91ce0bfc251e844ae7270a312"/></figure><p data-pid="5qRFvjKF"><b>该网络有一个输入层，用于接受数据的输入。<span class="nolink">隐藏层</span>用于从数据中查找任何隐藏的特征。然后输出层提供预期的输出。</b></p><p data-pid="Khnaryhe">这是一个使用大量未标记的眼睛视网膜数据的神经网络的示例。<span class="nolink">网络模型</span>根据这些数据进行训练，以确定一个人是否患有<span class="nolink">糖尿病视网膜病变</span>。<br/> </p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-6c70a579fa441fa0d99880e25e574a3b_b.jpg" data-caption="" data-size="normal" class="content_image" data-original-token="v2-6c70a579fa441fa0d99880e25e574a3b"/></figure><p data-pid="JAD5Etpn">现在我们已经了解了什么是深度学习，让我们看看它是如何工作的。</p><h2>深度学习如何工作？</h2><ol><li data-pid="UeR5QZl9"><b>计算加权和。</b></li><li data-pid="KTtgElHu"><b>计算出的权重总和作为输入传递给<span class="nolink">激活函数</span>。</b></li><li data-pid="tKf3fKFz"><b>激活函数将「输入的加权和」作为函数的输入，添加偏差，并决定是否应该激发神经元。</b></li><li data-pid="r-3k_oQI"><b>输出层给出预测输出。</b></li><li data-pid="4yYReMmj"><b>将模型输出与实际输出进行比较。训练神经网络后，模型使用反向传播方法来提高网络的性能。<a href="https://www.zhihu.com/search?q=%E6%88%90%E6%9C%AC%E5%87%BD%E6%95%B0&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3172224248%7D" class="internal">成本函数</a>有助于降低错误率。</b></li></ol><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-65b1dabb5dd4e11e36867dd93d2b1d1e_b.jpg" data-caption="" data-size="normal" class="content_image" data-original-token="v2-65b1dabb5dd4e11e36867dd93d2b1d1e"/></figure><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-46de51a5281936cebdf957b91fa97a90_b.jpg" data-caption="" data-size="normal" class="content_image" data-original-token="v2-46de51a5281936cebdf957b91fa97a90"/></figure><p data-pid="JNjutX1t">在下面的示例中，深度学习和神经网络用于识别车牌上的号码。许多国家都使用这种技术来识别违规者和超速车辆。<br/> </p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-6f3bfdacb409997ae1f9474ccc15f634_b.jpg" data-caption="" data-size="normal" class="content_image" data-original-token="v2-6f3bfdacb409997ae1f9474ccc15f634"/></figure><p data-pid="2XkQPXC-">想要入门深度学习或者找深度学习的相关资料，不如看看我写的这一篇文章，回答了深度学习相关资源、图书；以及学习下方法和路线。</p><a href="https://www.zhihu.com/question/36675272/answer/3149048176" data-draft-node="block" data-draft-type="link-card" data-image="https://pic3.zhimg.com/v2-e31bfbce487a66e4b6165111f287c4c2_qhd.jpg" data-image-width="275" data-image-height="183" class="internal">有哪些优秀的深度学习入门书籍？需要先学习机器学习吗？</a><p data-pid="7WZfGt76">本文作者：@TopGeeky<br/> </p>
666172193,354a091a04e0c20269578c0064f8d2a4,AI技能研究所,https://api.zhihu.com/people/354a091a04e0c20269578c0064f8d2a4,people,程序员的进阶之旅,入门<em>人工智能</em>需要学习哪些基础知识？,article,https://api.zhihu.com/articles/666172193,我当初研究生在学习<em>人工智能</em>的时候，就是因为一些基础知识掌握的不行，走了很多弯路！在硬生生走的过程中，我慢慢入门了<em>人工智能</em>，积累了一些经验，为了不让大家再重蹈我的老路，这个回答我就好好给大家分享一下！ <em>人工智能</em>是 计算机科学的一个分支，它是一个很大的方向。从<em>人工智能</em>的研究范围就可见一斑,153,7,0,1699604986,1708683952,<p data-pid="ND-ou-Gs"><b>我当初研究生在学习人工智能的时候，就是因为一些基础知识掌握的不行，走了很多弯路！</b></p><p data-pid="b7V59GAb">在硬生生走的过程中，我慢慢入门了人工智能，积累了一些经验，为了不让大家再重蹈我的老路，这个回答我就好好给大家分享一下！</p><p data-pid="8lw-eydL">人工智能是<span class="nolink">计算机科学</span>的一个分支，它是一个很大的方向。</p><p data-pid="Uh7baUME">从人工智能的研究范围就可见一斑，它是一门研究如何使计算机能够模拟且实现<span class="nolink">人类智能</span>的学科。</p><p data-pid="65Ea_faE">直白点说就是，它通过模拟人的认知过程和思维意识，使计算机具有类似人的智力水平，去做人可以做的事情。</p><p data-pid="4p3sKv1B">要达成这个目的，要做方方面面的努力，这又使得人工智能产生了很多的分支。<br/> </p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-635224cd74234b3a1a8a3c3e08073e5d_b.jpg" data-caption="" data-size="normal" data-rawwidth="720" data-rawheight="360" class="origin_image zh-lightbox-thumb" width="720" data-original="https://pic2.zhimg.com/v2-635224cd74234b3a1a8a3c3e08073e5d_r.jpg" data-original-token="v2-635224cd74234b3a1a8a3c3e08073e5d"/></figure><p data-pid="VtBN85PW">比如如何模拟人的认知过程和思维意识，帮助计算机能像人类那样思考，就产生了「<b>机器学习</b>」这门计算机理论。</p><p data-pid="2MOL4xpA">通过训练数据和算法模型让机器具有人工智能的方法，比如大家都知道的深度学习，是机器学习的其中一个研究方向，它是使用<span class="nolink">神经网络</span>模拟人类大脑的工作方式。</p><p data-pid="tvwbv-xe">比如如何让计算机和人对话，这就需要计算机能够理解人类语言的含义，并进行回复，这就产生了 NLP 「<b><a href="https://www.zhihu.com/search?q=%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">自然语言处理</a></b>」。</p><p data-pid="QbL4LmwI">用来研究计算机与人类自然语言之间的交互，比如一些智能客服，问答系统，手机上常用的 Hi Siri。</p><p data-pid="f3G_yu4B">比如如何让计算机具备感知视觉信息，理解它看到的东西，就产生了「<b><a href="https://www.zhihu.com/search?q=%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">计算机视觉</a></b>」。</p><p data-pid="jFDZOgVo">从图像或视频中提取有用的特征，进行识别、分析和理解，现在应用在视频监控、自动驾驶、<a href="https://www.zhihu.com/search?q=%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">医学影像</a>诊断等方面。</p><p data-pid="tZeHNdtt">比如通过<a href="https://www.zhihu.com/search?q=%E6%99%BA%E8%83%BD%E4%BD%93&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">智能体</a>与环境的交互学习最优行为的「强化学习」，比如改进人与机器之间交互方式的「<b><a href="https://www.zhihu.com/search?q=%E4%BA%BA%E6%9C%BA%E4%BA%A4%E4%BA%92&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">人机交互</a></b>」，比如...</p><p data-pid="LhMiKnO5">这些都是人工智能领域中的研究方向。<br/> </p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-a6fb882ea416e648593d0021060867ac_b.jpg" data-caption="" data-size="normal" data-rawwidth="604" data-rawheight="330" class="origin_image zh-lightbox-thumb" width="604" data-original="https://pic1.zhimg.com/v2-a6fb882ea416e648593d0021060867ac_r.jpg" data-original-token="v2-a6fb882ea416e648593d0021060867ac"/></figure><p data-pid="mdEtOlgI">随着人工智能的快速发展，ChatGPT、<span class="nolink">GPT-4</span> 等新产品和新技术的发布，再次让人工智能变的火热，在<a href="https://www.zhihu.com/search?q=%E5%A4%B8%E5%85%8B&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">夸克</a>发布的《2023 高考志愿》报告中，人工智能相关专业的关注度上升最快，我很高兴大家能够去关注 AI，尤其是在当今这个时代，AI 正在成为各行各业的核心驱动力。</p><p data-pid="PGWDMsny">我一直认为在当今，人人都应该去了解一下 AI 技术，借着这股技术热潮助力自己，当然我也听很多同学说有这个想法，但是不知道怎么去了解，正好最近<b>「知乎知学堂」</b>旗下<b>「AGI 课堂</b>」推出的<b>「程序员的 AI 大模型进阶之旅」</b>公开课，我建议大家去看一下，邀请的都是圈内的技术大佬解读最前沿的技术，只有两天的课程。</p><p data-pid="fO0QkdQ_">通过这个课好好了解像我们这样的普通人如何做 GPT 浪潮中的超级个体，一定<b>别忘了添加助教老师微信可以免费领 AI 大模型资料，不要白不要！</b></p><a data-draft-node="block" data-draft-type="edu-card" data-edu-card-id="1706347135925227520"></a><p data-pid="bGTVYmI8">不同的研究领域侧重点各不相同，需要的基础知识也是不同的。</p><p data-pid="RAZc0-hJ">你拿<b>机器学习</b>来说，它需要的基础知识：</p><p data-pid="HtDNBIPe">1、<a href="https://www.zhihu.com/search?q=%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">数学基础</a></p><p data-pid="sLSt1gVb">像微积分、线性代数、概率论与数理统计，用来理解和计算机器学习中算法的<a href="https://www.zhihu.com/search?q=%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">数学原理</a>与推导，以及<a href="https://www.zhihu.com/search?q=%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">优化方法</a>。</p><p data-pid="rnTwRNPI">2、编程基础</p><p data-pid="aBQPgWVm">掌握编程语言，用来实现机器学习的算法，比如 Python、R、C++ 等。</p><p data-pid="H4KqnVkG">3、<a href="https://www.zhihu.com/search?q=%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">数据结构与算法基础</a></p><p data-pid="7647_p51">机器学习算法中使用了很多的数据结构和算法，了解常用的数据结构与算法能更好的理解和实现机器学习算法和模型。</p><p data-pid="Peo6MAXO">你像<b>自然语言处理</b>，它需要的基础知识：</p><p data-pid="k3vajtTT">1、数学基础</p><p data-pid="xgxUdqgU">微积分、线性代数、概率论与数理统计这些内容，有助于理解 NLP 模型以及学会用它们来处理文本数据，</p><p data-pid="gWU7FsLe">2、编程基础</p><p data-pid="2FCh9io7">掌握编程语言，常见的是 Python、C++ 这些可以用来编写和运行程序。</p><p data-pid="CG5prqs3">3、数据结构与算法基础。</p><p data-pid="5cxlVEF7">数据结构和算法对于处理和分析文本数据非常重要，掌握常见的数据结构与算法能让自己写出更高效的 NLP 算法和模型。</p><p data-pid="_eGfX9uh">4、语言学基础</p><p data-pid="vutDjxM_">这个是学习自然语言处理必须的，了解基本的语言学概念和语言结构，比如像语法、句法、语义，对于自然语言处理来说是很重要的。</p><p data-pid="6U_yKSfj">再者像计算机视觉，它需要的基础知识：依然是数学基础、编程基础、数据结构与算法基础以外，你需要额外具有<a href="https://www.zhihu.com/search?q=%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">数字图像处理基础</a>，熟悉数字图像技术处理的基本技术。</p><p data-pid="ZtbiiEiu">因为篇幅原因，再多就不列了。</p><p data-pid="hwo5bjPW">你可以看到，人工智能的每个研究方向具体要做的内容不同，具体要求可能也会有所不同，但还是存在着交叉和重叠的知识内容。</p><p data-pid="yc4GK-LS">也就是<b>数学基础、编程基础、数据结构与算法</b>。</p><p data-pid="pSqWq2JY">这些也是学习人工智能所需要的前置知识，最好在你学习某个具体方向之前要快速学一下，只需要学习我们能用到的就好。</p><p data-pid="bPqq-Y97"><b>不要求到精通的程度，但最少你要了解</b>，起码在后续的学习中碰到这个知识，就算你不熟，也知道可以去哪里找到这个知识学。<br/> </p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-fba26896be35ca435d9c788c366fb6c1_b.jpg" data-caption="" data-size="normal" class="content_image" data-original-token="v2-fba26896be35ca435d9c788c366fb6c1"/></figure><h2>数学基础</h2><p data-pid="AS6XJ7MN">数学对于人工智能的学习至关重要，我们需要理解和应用相关的<a href="https://www.zhihu.com/search?q=%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">模型算法</a>，有了数学基础，可以帮助我们理解算法模型背后的数学原理，以及后续在训练模型或者<a href="https://www.zhihu.com/search?q=%E8%AF%84%E4%BC%B0%E6%A8%A1%E5%9E%8B&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">评估模型</a>时涉及的计算过程。</p><p data-pid="bsehoWWk">大家也不要害怕，主要的就是微积分、线性代数、<a href="https://www.zhihu.com/search?q=%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">概率论与数理统计</a>，这都是大学中学过的数学课程。</p><p data-pid="ZnqPJmVS">1、微积分</p><p data-pid="h5hqQSnh">微积分是高数中的内容，重点是在<a href="https://www.zhihu.com/search?q=%E5%BE%AE%E5%88%86&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">微分</a>方面，重点看一下极限、导数、<a href="https://www.zhihu.com/search?q=%E5%81%8F%E5%AF%BC%E6%95%B0&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">偏导数</a>、梯度。</p><p data-pid="nWjrhgjL">2、线性代数</p><p data-pid="TgCiLoZ7">线性代数对于人工智能的学习很重要，涉及到很多<a href="https://www.zhihu.com/search?q=%E7%9F%A9%E9%98%B5&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">矩阵</a>的运算，重点在向量、矩阵、线性方程组、特征值、<a href="https://www.zhihu.com/search?q=%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">特征向量</a>。</p><p data-pid="4s59Fu0k">3、概率论与数理统计</p><p data-pid="33pnSk5J">人工智能中很多算法涉及到概率论与数理统计中的内容，比如<a href="https://www.zhihu.com/search?q=%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">最大似然估计</a>，高斯分布。</p><p data-pid="4qMWgjhK">这里需要看概率分布(正态分布、均匀分布、<a href="https://www.zhihu.com/search?q=%E4%BC%AF%E5%8A%AA%E5%88%A9%E5%88%86%E5%B8%83&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">伯努利分布</a>)、抽样分布(t 分布、<a href="https://www.zhihu.com/search?q=%E5%8D%A1%E6%96%B9%E5%88%86%E5%B8%83&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">卡方分布</a>)、统计量(均值、方差、置信区间)、<a href="https://www.zhihu.com/search?q=%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">假设检验</a>等。</p><p data-pid="XNQ4kP5f">看着挺多，其实都是学过的内容，重新复习一下就想起来。</p><h2>编程基础</h2><p data-pid="vtnErCrS">编程这个的重要性就不必多说了吧，不会编程啥也干不了。</p><p data-pid="2Pe8MQIO">刚开始你就先掌握 Python 就好了，Python 具有完善的人工智能生态系统，很多模型的代码都是基于 Python 实现的。</p><p data-pid="Pm6NaFx-">各种配套的第三方库和工具也很完善，比如强大的数据处理库 Numpy、Pandas，比如丰富的<a href="https://www.zhihu.com/search?q=%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">数据可视化</a>库 Matplotlib、Seaborn。</p><p data-pid="_NhcRMpY">如何学习 Python，提高 Python 的编程能力，不是本文的重点，可以看下面这个回答：</p><a href="https://www.zhihu.com/question/553628459/answer/2689874048" data-draft-node="block" data-draft-type="link-card" data-image="https://pic4.zhimg.com/v2-c11a85e9ec73b235adb557b7de9235b3_l.jpg" data-image-width="300" data-image-height="300" class="internal">怎样提高自己的 Python 编程能力？</a><p data-pid="WJB2Bq2r"><br/>后续等你到了一个更高的阶段，应该也会用到 C++，它是一种<a href="https://www.zhihu.com/search?q=%E7%BC%96%E8%AF%91%E5%9E%8B%E8%AF%AD%E8%A8%80&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">编译型语言</a>，可以<a href="https://www.zhihu.com/search?q=%E7%9B%B4%E6%8E%A5%E8%AE%BF%E9%97%AE&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">直接访问</a>和控制底层硬件以及内存，进行精细化的<a href="https://www.zhihu.com/search?q=%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">内存管理</a>和优化，在处理大规模数据时至关重要。</p><p data-pid="vo46SVXL">关于 C++ 的学习路线，我先给大家放在下面，需要的时候可以回头来看：<br/></p><a href="https://zhuanlan.zhihu.com/p/435927070" data-draft-node="block" data-draft-type="link-card" data-image="https://pic4.zhimg.com/v2-c6d1bf41be595f4697e082a6ace6033f_qhd.jpg" data-image-width="1360" data-image-height="579" class="internal">Rocky0429：这才是你最想要的 C++ 学习路线</a><h2>数据结构与算法</h2><p data-pid="LiBfqhCp">在本科阶段，数据结构与算法就是最重要的计算机基础课之一，不管是后续考研还是找工作都很重要，没想到吧，在人工智能的学习中，数据结构与算法依然重要。</p><p data-pid="h5bkp961">比如常见的社交网络分析，需要使用<a href="https://www.zhihu.com/search?q=%E5%9B%BE%E7%AE%97%E6%B3%95&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">图算法</a>处理和分析复杂的图结构数据，使用<a href="https://www.zhihu.com/search?q=%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">搜索算法</a>解决<a href="https://www.zhihu.com/search?q=%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">推荐系统</a>问题，或者使用<a href="https://www.zhihu.com/search?q=%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">排序算法</a>生成最终的推荐结果。</p><p data-pid="T8REbT5O">对于学习人工智能的同学，或者想以后走研究这条路，数据结构与算法一定要<a href="https://www.zhihu.com/search?q=%E5%A6%82%E8%87%82%E4%BD%BF%E6%8C%87&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3171801327%7D" class="internal">如臂使指</a>。</p><p data-pid="6r57r_Yq">数据结构主要就是数组、链表、栈、队列和树等。</p><p data-pid="2VBuZ1em">算法重要的就是排序算法、搜索算法、图等。</p><p data-pid="oPX8ImiA">如果你想详细的学习数据结构与算法，可以<span class="nolink">看这里</span>：</p><a href="https://zhuanlan.zhihu.com/p/582109772" data-draft-node="block" data-draft-type="link-card" data-image="https://pic3.zhimg.com/v2-d8dbf58ad1ac56aeecfe35f5bd86ce2e_qhd.jpg" data-image-width="1370" data-image-height="681" class="internal">Rocky0429：这才是你最想要的数据结构与算法学习路线</a><p data-pid="MOaSOKGh"><br/>最低要求就是大家一定要掌握原理，至于暂时写不出来，也没关系。</p><p data-pid="sz899us0">写在最后</p><p data-pid="taM4sPuf">把前置技能花点时间准备好，等你具体研究哪个方向，再去学对应方向的知识。</p><p data-pid="ynMWhCod">当然不管你是出于什么目的想要学习人工智能，不管以后你是不是要从事相关行业，我都希望你能在有时间去学习的时候，多多了解一下 AI，<b>「知乎知学堂」</b>旗下<b>「AGI 课堂</b>」的这个<b>「程序员的 AI 大模型进阶之旅</b>」公开课一定可以帮助到你！</p><p data-pid="vYK5Edxn">两天的课程，找到可以借助 AI 帮助自己破局的方法，做 GPT 浪潮中的超级个体！</p><a data-draft-node="block" data-draft-type="edu-card" data-edu-card-id="1706347058565484544"></a><p data-pid="DUQNXC64">之前看到一句很有意思的对话：</p><p data-pid="5pGICUCd">问</p><p data-pid="PgIM3Fej">人工智能的巅峰是什么？</p><p data-pid="GJEO2UHi">答</p><p data-pid="evAvS2jJ">人工智能的巅峰时 AI 们集体讨论该如何解决人类问题。</p><p data-pid="N2418nQY">想象一下，如果 AI 们来到知乎提出这样的问题：「学习人类需要哪些基础知识」，那会是怎样一副场景？</p><p data-pid="4oSAsaGq">画面太美，难以想象。</p><p data-pid="N_cdG28J">本文作者：@Rocky0429</p>
696657542,26312c6a6eeb0a3812e169746daa05f9,联参智库,https://api.zhihu.com/people/26312c6a6eeb0a3812e169746daa05f9,people,海陆空天电磁网各域作战概念、装备、技术研究。,<em>人工智能</em>在俄罗斯与西方对抗中发挥的作用,article,https://api.zhihu.com/articles/696657542,新美国安全中心（CNAS）发表了关于俄罗斯在<em>人工智能</em>（<em>AI</em>）领域取得的进展及其与西方对抗中所扮演角色的深入分析报告。报告探讨了俄罗斯对AI的看法、目标、在乌军事行动对AI发展的影响、俄罗斯AI研发的推动因素与限制因素,0,0,0,1715177745,1715177745,<p data-pid="bf9yddOi"><span>2024年4月，新美国安全中心（CNAS）发表了关于俄罗斯在人工智能（AI）领域取得的进展及其与西方对抗中所扮演角色的深入分析报告。报告<span>探讨了俄罗斯对AI的看法、目标、在乌军事行动对AI发展的影响、俄罗斯AI研发的推动因素与限制因素，以及俄罗斯与国际社会在AI领域的合作关系。</span></span></p><p><figure><img src="https://pic3.zhimg.com/v2-740e5071ef531c4a664d6846b7f5873a_b.jpg" alt="图片" class="content_image" data-original-token="v2-740e5071ef531c4a664d6846b7f5873a"/></figure></p><p data-pid="y9V47XkM"><strong>从近期来看，俄罗斯军方认为必须牢牢掌控AI</strong></p><p data-pid="Ucbdyu4J"><span>俄罗斯认识到AI在现代战争中的重要性，已在多个领域进行了数十年研发。俄罗斯国防部投资于AI相关的研究、开发、试验与鉴定（RDT&amp;E），特别是在乌克兰战场上的应用。俄罗斯国防部正在投资开发并最终应用于空中、海上和地面领域的不同类型的无人巡航系统。俄罗斯认为自己在与主要大国的技术竞争中落后，总统普京强调AI对国家安全的重要性，并呼吁国内加强AI研发，以减少对进口技术的依赖。俄罗斯军方预测，未来战争将由AI主导，而人类在战争中的作用将逐渐减少。</span></p><p data-pid="-2Fhc2jn"><span><strong>俄乌战争对俄罗斯造成负面影响，国际制裁亦施加了一定的挑战</strong></span></p><p data-pid="MYGcI28C"><span>尽管俄罗斯在乌克兰的军事行动暴露了其在武器系统和技术开发方面的不足，但俄罗斯政府正在加速AI的集中化发展，并加强军事与民用部门之间的合作。西方的制裁和出口管制增加了俄罗斯实现AI目标的难度。俄罗斯正通过追求进口替代和技术主权计划来减轻西方经济压力的影响。目前俄罗斯军方认为人类必须参与决策和控制循环。俄罗斯在AI领域的优先事项包括C4ISR和机器人技术、数据收集与智能化战争、信息和网络领域以及核力量的管理和使用。尽管俄罗斯在乌克兰的军事挫折可能会增加其在高科技领域追赶西方的压力，但俄罗斯的AI能力仍对美国和国际政策制定者构成了挑战。俄罗斯可能会利用AI增强其不对称工具，特别是在其认为落后于西方的领域。</span></p><p data-pid="9WaWPu2v"><span><strong>俄罗斯的AI发展及军民合作</strong></span></p><p data-pid="xYzAkrYu"><span>俄罗斯在AI领域的投资集中于当前和未来战斗中最相关的领域，包括指挥控制、通信、计算机、情报、监视和侦察（C4ISR）系统，以及使用AI进行数据收集和分析。俄罗斯政府强调在信息和网络作战中使用AI，并可能在核力量的指挥、控制、管理和使用中应用AI。同时，俄罗斯也在寻求与中国在AI技术和政策发展方面进行合作。</span></p><p data-pid="V5IO4HZu"><span><strong>未来展望与国际合作</strong></span></p><p data-pid="JFwJDFbm"><span>尽管俄罗斯在乌克兰战场上面临挑战，但它仍在致力于AI的发展，这需要西方的密切关注。俄罗斯将继续作为一个拥有AI能力的大国，其AI能力在战场上和更广泛的对抗西方的冲突中构成挑战。俄罗斯预计会增加与未参与国际制裁制度的国家的合作，特别是在中东、东南亚和拉丁美洲。俄罗斯在AI领域的合作伙伴包括白俄罗斯、以色列、印度和中国等。</span></p><p data-pid="a-nkEhUv"><span><strong>结语</strong></span></p><p data-pid="8P-KdL7V">俄罗斯政府、军队和社会如何应对由乌克兰持续冲突引起的重大重组和再发展，将是未来观察的重点。这包括俄罗斯如何在国际舞台上寻求新的合作伙伴关系，以及它如何利用AI技术来提升其全球地位和影响力。整体而言，俄罗斯的AI发展策略和其在军事及民用领域的应用，将继续是国际社会关注的焦点。</p><p data-pid="9G8ntNyO"><span>报告原文已在联合作战情报参考网分享，请点击原文链接下载。</span></p><hr/><p data-pid="GKvkZCfk"><span>联参智库现有全球军事领域</span><span>情报资料</span><span>80万份，纵向贯穿战略规划、条令法规、指南手册、标准报告，横向覆盖全球主要50个防务智库报告。</span></p><p data-pid="Slo3H75J"><span>资料专题，</span><span>作战概念、指挥控制、无人系统、人工智能，试验鉴定等；</span></p><p data-pid="1v9eHQAi"><span>数据产品，</span><span>如全球武装力量数据、军用无人机数据等；</span></p><p data-pid="BO1MamPg"><span>软件产品</span><span>，如全球装备参数数据库、全球现代军用飞机数据库等；</span></p><p data-pid="AV-62m3n"><span>译文产品</span><span>，如参联会系列文件、联合部队作战与条令等；</span></p><p data-pid="q4_-bwmb"><span>研究报告</span><span>，</span><span>如世界无人作战力量建设、星链反制等。</span></p><p><span><br/></span></p><blockquote data-pid="aux6A0bJ"><p data-pid="btKP_7A0">本文使用 <a href="https://zhuanlan.zhihu.com/p/358098152" class="internal">文章同步助手</a> 同步</p></blockquote>
696644230,ce18d576388c4604dd91107368f85cb6,Qs.Zhang张拳石,https://api.zhihu.com/people/ce18d576388c4604dd91107368f85cb6,people,张拳石 上海交大副教授 博导 可解释性机器学习 招博士后,<em>人工智能</em>疯了，学无道，富且贵焉，耻也,article,https://api.zhihu.com/articles/696644230,2023年当大部分人撤离了刷榜的阵地之后，<em>人工智能</em>越来越疯了，也要把我逼疯了，或许有一天我会以其他的形式留在学术界，而不是陪着大家演戏。我希望严肃的面对这个世界,43,8,16,1715173184,1715173350,<p data-pid="Qe6iW-yV">2023年当大部分人撤离了刷榜的阵地之后，人工智能越来越疯了，也要把我逼疯了，或许有一天我会以其他的形式留在学术界，而不是陪着大家演戏。我希望严肃的面对这个世界，无奈台面上很多论文放弃了起码的准则，论文背后的学者、舆论、科研攻略一齐编织着皇帝的新衣。</p><p data-pid="22UEo3_D">在多少交流场合，面向不同的学者的各式论文，我常常两句话打断你的报告，然后用5秒钟说出这一流派的根本问题，而你立马用10秒钟回复自己的无能为力，惊愕于我揭开整个方向的新衣，但是依然坚持你们中了很多论文而且，档次还是顶级。原谅我难以融入你们的默契。闭上嘴的南郭先生总是比抚起琴的阮籍看上去权威一些，但是耻也。</p><p data-pid="mNa0W-2E"><b>就让我说说最近读到的顶级刊物的顶级论文。</b></p><p data-pid="VLRQ14dm">论文1：关于深度学习中某个问题有个思考A，针对这个思考A提出了验证性实验（或验证性指标）B，基于前面的实验得到了新的insight C，然后提出算法D，解决了C的问题。但是A于B之间没有五服以内的直接的亲缘（数学）关系，A于C之间也没有讨论相同范畴的事物，D在算法上并没有直接对C中的问题进行证明建模的讨论，而以一种无心插柳柳成荫的形式解决了C。</p><p data-pid="no4va57J">论文2：做了个实验，构造了复杂任务A，然后在A的基础上做了些调整，构造了一个不太复杂的任务B，然后发现神经网络模型果然在相对简单的任务上性能更好一些（然后提出不同角度、不同指标论证这个结论），原因是B中给出了一些“捷径特征”——然后实验中果然发现了神经网络学到了这些捷径，这就是成果。</p><p data-pid="5csnpEDO">论文3：我们把这个模型在A、B、C、D、E等等不同任务上做了测试，发现此模型在A、B、C上新能比较好，而没有能力建模D、E等任务。记得16年，我审稿过程中，类似的实验发现被多个审稿人联合拒稿，理由是这些结论都是众所周知的，没有创新。</p><p data-pid="O53c9CVX">论文4：我发现了反直觉现象，把在A上训练一下，然后在B上微调一下，效果真好。然后A跟B看上去没有什么关系。</p><p data-pid="Af_nFfNh">论文5：我发现了一个结论C。但是C究竟是什么，好像说不清楚，似是而非，没有数学描述，没有定义的边界。motivation的哲学，实验设计凭直觉，得出的结论。。。</p><p data-pid="3XiIis0k">论文6：是一篇理论，看上去挺唬人了。然后经验上大概30%的论文都可以证明出明显的错误。还有些论文十多年都没有真正影响过应用。</p><p data-pid="sNoTtVwE"><b>为什么不给自己立一些原则呢？</b></p><ol><li data-pid="gIlImynF">当看到在炼丹框架下的方法论很难得到根本性的突破，为什么不阻止自己做这些类型呢？</li><li data-pid="uZ5M7qI2">说说XAI方向：工程性post-hoc explanation of DNNs无法给出严谨的解释，无法在重大应用中给出绝对的、可靠的评估，已经是七八年以来的共识了，为什么在大量position papers发表以后，大量工程性解释算法还是持续地发表呢？为什么不静下来想一想踏踏实实的核心问题呢？</li><li data-pid="CkpA5eR3">暂且不提创新性，有些论文的结论是correct，有些论文的结论是wrong，但是很大一部分论文not even wrong（可能一些人不清楚这是什么意思）。</li><li data-pid="IF7uKTPn">当无法对一个现象或结论的边界范围做出数学上的描述时，能不能先不急于把这个结论公布到学术界。可以只有实验而没有证明，但是对论题本身是不是要有个清晰的界定。</li></ol><p data-pid="1h_ryHDb">对上述原则的坚持，在审稿过程中甚至常常成为拒稿的原因。</p><p data-pid="otsELF-Z"><b>何去何从</b></p><p data-pid="rYRz-b81">我记得2023年10月的时候，就跟一些同学和同事聊到过我的一个预测。当一个领域中30%-50%以上的论文无法（甚至没有资格）作为另一篇论文的基础时，这个领域的口碑就会急转直下，因为大家会发现很大一部分研究不会直接为领域的发展给出直接的贡献了。这里，甚至可以不考虑因为性能不济而不被引用的问题，而是很多论文中似是而非的结论根本无法被清晰地明确提炼出来，给出一个明确的指引。</p><p data-pid="_EHSMzUz">我认为这个时间点在2026年以前。</p><p data-pid="DEi1a_5E"><b>大家都说很多工程性实验论文可以给出一些启发式的insights，为未来的扎实理论突破做铺垫。这是一个美好的幻想。</b>除了一些及其浮夸的无法严格验证其普适性的现象孤例以外，绝大部分insights与2016年的认知并没有本质的拓展。</p><p data-pid="RboDx0Ie">大家在忙着各种事儿，忙着在规则体系内寻找向上的路径，但是对这个规则没有质疑和反思。这样的现象遍布全球，科举文化下尤甚。</p><p data-pid="1L8g3b6h">看到一个扩张的时代，就如当年的大炼钢铁，大家都清楚领域中在做什么，但是没有人高声说哪怕一句话，不断地新建、扩张、捷报频传，等着2026的到来。世上何曾有过什么荣耀，不滑稽自欺已是千难万难。</p><a href="https://zhuanlan.zhihu.com/p/661781861" data-draft-node="block" data-draft-type="link-card" class="internal">Qs.Zhang张拳石：这两年，我究竟做了些什么（2021-2023）</a><a href="https://zhuanlan.zhihu.com/p/694930219" data-draft-node="block" data-draft-type="link-card" class="internal">Qs.Zhang张拳石：神经网络可解释性研究中常被忽略的几个根本问题</a><a href="https://zhuanlan.zhihu.com/p/618870800" data-draft-node="block" data-draft-type="link-card" data-image="https://pic1.zhimg.com/equation_l.jpg" data-image-width="120" data-image-height="120" class="internal">Qs.Zhang张拳石：AI从技术到科学：神经网络中的概念符号涌现的发现与证明</a><a href="https://zhuanlan.zhihu.com/p/693747946" data-draft-node="block" data-draft-type="link-card" data-image="https://pic3.zhimg.com/equation.jpg" data-image-width="120" data-image-height="120" class="internal">Qs.Zhang张拳石：证明神经网络精细决策逻辑可以严格解释为符号化等效交互概念</a><a href="https://zhuanlan.zhihu.com/p/546433296" data-draft-node="block" data-draft-type="link-card" class="internal">Qs.Zhang张拳石：敢问深度学习路在何方，从统一12种提升对抗迁移性的算法说起</a><a href="https://zhuanlan.zhihu.com/p/610774894" data-draft-node="block" data-draft-type="link-card" data-image="https://pic1.zhimg.com/v2-b5d0ae71e32b557fa1f00e2176b27614_l.jpg" data-image-width="356" data-image-height="381" class="internal">Qs.Zhang张拳石：神经网络可解释性：正本清源，论统一14种输入重要性归因算法</a><a href="https://zhuanlan.zhihu.com/p/524075490" data-draft-node="block" data-draft-type="link-card" class="internal">Qs.Zhang张拳石：可解释性理论系列：反思深度学习，去伪存真、合众归一198 赞同 · 16 评论文章211 赞同 · 17 评论文章220 赞同 · 17 评论文章</a><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/KXdSwv_ypx1l2AIHrVb-3A" data-draft-node="block" data-draft-type="link-card" class=" wrap external" target="_blank" rel="nofollow noreferrer">上交大张拳石：深度学习可解释性，从百家争鸣到合众归一​mp.weixin.qq.com/s/KXdSwv_ypx1l2AIHrVb-3A​mp.weixin.qq.com/s/KXdSwv_ypx1l2AIHrVb-3A​mp.weixin.qq.com/s/KXdSwv_ypx1l2AIHrVb-3A​mp.weixin.qq.com/s/KXdSwv_ypx1l2AIHrVb-3A</a><a href="https://zhuanlan.zhihu.com/p/468569001" data-draft-node="block" data-draft-type="link-card" class="internal">Qs.Zhang张拳石：ICLR 2022 Oral论文中得分排名前五的高分论文“发现并证明神经网络表征瓶颈”（得分10,8,8,8）923 赞同 · 25 评论文章995 赞同 · 25 评论文章1030 赞同 · 25 评论文章1067 赞同 · 26 评论文章</a><a href="https://zhuanlan.zhihu.com/p/264871522/" data-draft-node="block" data-draft-type="link-card" class="internal">Qs.Zhang张拳石：神经网络的博弈交互解释性（一）：前言，漂在零丁洋里的体系268 赞同 · 20 评论文章275 赞同 · 20 评论文章</a><ol><li data-pid="deTZQv7K"><a href="https://zhuanlan.zhihu.com/p/264871522/" class="internal">前言，漂在零丁洋里的体系</a></li><li data-pid="IgTgQmt7"><a href="https://zhuanlan.zhihu.com/p/264953129" class="internal">博弈交互概念、定义、定理、推论、与计算</a></li><ol><li data-pid="U3nCmMrt">动机：建模知识，连接性能</li><li data-pid="kpScejAR">背景基础Shapley value</li><li data-pid="DUYTY6S_">双变元博弈交互</li><li data-pid="xMwYfqEX">多变元博弈交互，及其近似计算</li><li data-pid="pGmThpFN">多阶博弈交互</li><li data-pid="9tw8hOQV">相关定理与推论</li><li data-pid="dD_7tHMU">自然语言交互树</li></ol><li data-pid="Pyurx0_-"><a href="https://zhuanlan.zhihu.com/p/386548661/" class="internal">博弈交互与知识表达的关</a></li><ol><li data-pid="LR0TVdxP">探索中低阶博弈交互所建模的视觉概念及泛化能力</li><li data-pid="Jh3fnZrd">探索高阶博弈交互所建模的视觉概念</li><li data-pid="xn1IgG55">神经网络对纹理概念的建模相比形状概念更具有弹性</li></ol><li data-pid="vajxBLL8"><a href="https://zhuanlan.zhihu.com/p/264873308/" class="internal">博弈交互与对抗攻击的关系，推导证明与实验</a></li><ol><li data-pid="Pk3AVwhY">证明博弈交互与对抗迁移性的负相关关系</li><li data-pid="2_d_XsGI">证明多个前人迁移性增强算法可近似归纳解释为对博弈交互的抑制</li><li data-pid="mXKvNbvp">交互<a href="https://www.zhihu.com/search?q=%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2928247749%7D" class="internal">损失函数</a>与迁移性的增强</li></ol><li data-pid="I0KGpkbe"><a href="https://zhuanlan.zhihu.com/p/345561960" class="internal">博弈交互与泛化能力的关系，推导证明与实验</a></li><ol><li data-pid="SnToekAD">探索交互强度与泛化能力的关系</li><li data-pid="jjAOyVXo">证明Dropout对交互强度的抑制</li><li data-pid="qT4fxLqD">交互强度损失函数与泛化能力的提升</li></ol><li data-pid="RdGweTF8"><a href="https://zhuanlan.zhihu.com/p/361686461" class="internal">从博弈交互层面解释对抗鲁棒性</a></li><ol><li data-pid="j2LvfXZO">对抗攻击在多阶博弈交互上的效用</li><li data-pid="0uj5nzXT">从知识构成的层面探索对抗训练提升鲁棒性的原因</li><li data-pid="I5SoZXNw">去芜存菁：解释并萃取多个前人防御算法中公共的有效机理</li></ol><li data-pid="_EZ7fBo9"><a href="https://zhuanlan.zhihu.com/p/369883667" class="internal">神经网络对抗迁移性：从神农尝百草到精炼与萃取</a></li><li data-pid="s3-KfN9z"><a href="https://zhuanlan.zhihu.com/p/395674023/" class="internal">完善Shapley value理论体系，建模并学习基准值</a></li><li data-pid="XiyCfdL1"><a href="https://zhuanlan.zhihu.com/p/395709713" class="internal">在博弈交互体系内，对“美”提出一个假设性建模</a></li><li data-pid="yw-xwvK-"><a href="https://zhuanlan.zhihu.com/p/422420088/" class="internal">可解释性核心——神经网络的知识表达瓶颈</a></li><ol><li data-pid="PSSDEbMK">博弈交互与神经网络知识表征</li><li data-pid="kgg3JQOR">发现并理论解释神经网络的表达瓶颈</li><li data-pid="e6f05QyN">突破表达瓶颈及探究不同交互复杂度下的表达能力</li></ol><li data-pid="I85KMje9"><a href="https://zhuanlan.zhihu.com/p/546433296/" class="internal">敢问深度学习路在何方，从统一12种提升对抗迁移性的算法说起</a></li><li data-pid="2pr8dwOr"><a href="https://zhuanlan.zhihu.com/p/610774894/" class="internal">神经网络可解释性：正本清源，论统一14种输入重要性归因算法</a></li><li data-pid="q6A1hPVd"><a href="https://zhuanlan.zhihu.com/p/633531725" class="internal">对智能模型中概念涌现的证明</a></li><li data-pid="QWJExtCA"><a href="https://zhuanlan.zhihu.com/p/626642885" class="internal">数学证明神经网络中符号化概念涌现的现象</a></li><li data-pid="kbMZ17eP"><a href="https://zhuanlan.zhihu.com/p/643213054" class="internal">可解释的哈萨尼网络</a></li><li data-pid="3FVs7_t7">通过博弈交互 某某某某某某</li><li data-pid="eAc2pKVE">通过博弈交互 某某某某某某</li></ol>
696643140,b25aca5efe1523a2ba8984f89efacf10,<em>AI</em>技术通,https://api.zhihu.com/people/b25aca5efe1523a2ba8984f89efacf10,people,,8个神奇的<em>人工智能</em>网站,article,https://api.zhihu.com/articles/696643140,随着<em>人工智能</em>的发展，越来越多的技术开始应用到现实生活中，今天我就给大家介绍8个神奇的<em>人工智能</em>网站 第一个 人工智能生成二次元角色 喜欢二次元的小伙伴，肯定都有属于自己的“老婆”,1,0,0,1715171474,1715171474,<p data-pid="d-UcEl0-">随着人工智能的发展，越来越多的技术开始应用到现实生活中，今天我就给大家介绍8个神奇的人工智能网站<br/></p><p data-pid="4sdacFb6">第一个</p><p data-pid="l_8rCZeg">人工智能生成二次元角色</p><p data-pid="kHqhWS9-">喜欢二次元的小伙伴，肯定都有属于自己的“老婆”，但是你的“老婆”都是存在于番剧之中和别人共享的，如果你想要一个属于自己独一无二的老婆那么这个网站可以轻松满足你的愿望。进入网站之后只需要调整好你的设置，就可以生成一个专属于你的角色了，据说有些本子作家在没有人物灵感的时候就会用这个网站来找灵感，属实方便</p><p data-pid="M7CAdYl-"><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-f92f0db3e67ed2b0bfb954313a11ade9_b.gif" data-rawwidth="1920" data-rawheight="1080" data-caption="" data-size="normal" data-thumbnail="https://pic2.zhimg.com/v2-f92f0db3e67ed2b0bfb954313a11ade9_b.jpg" class="origin_image zh-lightbox-thumb" width="1920" data-original="https://pic2.zhimg.com/v2-f92f0db3e67ed2b0bfb954313a11ade9_r.jpg" data-original-token="v2-f92f0db3e67ed2b0bfb954313a11ade9"/></figure>人工智能生成二次元角色</p><p data-pid="LANK4yv8">第二个</p><p data-pid="HdV8tpCZ">人工智能自动生成猫</p><p data-pid="tudSnsAA">如果说你对二次元角色不感兴趣，那么你不可能会对喵星人有抵抗力，这个网站可以使用人工智能自动生成一只不存在的猫，助力无猫人士云吸猫，虽然不能像生成二次元角色那样自定义猫的各类属性，不过刷新一下就生成一只猫的操作也是十分方便，就是在生成猫的这方面，这个AI偶尔会生成一些不那么像猫的猫，不过只要你认为那是猫，那肯定就是猫了</p><p data-pid="TY2RdjJz"><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-b9387fe04093e128b6849f3f6bce3100_b.gif" data-rawwidth="1920" data-rawheight="1080" data-caption="" data-size="normal" data-thumbnail="https://pic1.zhimg.com/v2-b9387fe04093e128b6849f3f6bce3100_b.jpg" class="origin_image zh-lightbox-thumb" width="1920" data-original="https://pic1.zhimg.com/v2-b9387fe04093e128b6849f3f6bce3100_r.jpg" data-original-token="v2-b9387fe04093e128b6849f3f6bce3100"/></figure>人工智能自动生成猫</p><p data-pid="hRCsPPe7">第三个</p><p data-pid="qAJ6xUvs">人工智能生成房子</p><p data-pid="ScyFwhwH">有猫有房有老婆才能算得上是完美的人生，前面介绍了老婆和猫，接下来就介绍一个可以用人工智能自动生成房子的网站吧！这个网站每次刷新都可以得到一个属于你的房子，生成的房子里面会有不同的布局，家具，这个网站甚至还会给你生成的房子打造一个关于这个房子的信息</p><p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-dfd15eefd82f9126106cfc6ea2abcc56_b.jpg" data-rawwidth="640" data-rawheight="360" data-caption="" data-size="normal" class="origin_image zh-lightbox-thumb" width="640" data-original="https://pic3.zhimg.com/v2-dfd15eefd82f9126106cfc6ea2abcc56_r.jpg" data-original-token="v2-dfd15eefd82f9126106cfc6ea2abcc56"/></figure></p><p data-pid="yIAxeqS3">第四个</p><p data-pid="NOmwaEQA">人工智能一键抠图</p><p data-pid="OZLLcYFc">如果说前面几个网站只停留在视觉方面，那么接下来的网站都将会非常实用。Remove bg是一款相当厉害的免费抠图网站，只要五秒钟就可以将背景完美去除，而且使用十分简单，只需要将图片拖入网站，等待一会之后图片就可以立马扣好，当然，对于它来说，太复杂的图片还是有点难度</p><p data-pid="WmxpKlN-"><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-93e2e138ddd610705937e89ac1b214b3_b.gif" data-rawwidth="639" data-rawheight="361" data-caption="" data-size="normal" data-thumbnail="https://pic4.zhimg.com/v2-93e2e138ddd610705937e89ac1b214b3_b.jpg" class="origin_image zh-lightbox-thumb" width="639" data-original="https://pic4.zhimg.com/v2-93e2e138ddd610705937e89ac1b214b3_r.jpg" data-original-token="v2-93e2e138ddd610705937e89ac1b214b3"/></figure>人工智能一键抠图</p><p data-pid="l0oxLgzM">第五个</p><p data-pid="9NLCjHf0">线稿自动上色</p><p data-pid="6BpaNx4O">只要上传一幅黑白线稿，这个网站就会自动给这个线稿上色，并且色彩过渡十分自然，毫无违和感可言，除了自动上色之外，这个你也可以选择自己喜欢的颜色让这个网站给你自动上色，不知道对于插画师来说心中是喜还是忧，但是相信有不少小伙伴心中有大胆的想法了吧！</p><p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-1a0e463d2d33e24b745e7b42ba5715fc_b.gif" data-rawwidth="639" data-rawheight="361" data-caption="" data-size="normal" data-thumbnail="https://pic1.zhimg.com/v2-1a0e463d2d33e24b745e7b42ba5715fc_b.jpg" class="origin_image zh-lightbox-thumb" width="639" data-original="https://pic1.zhimg.com/v2-1a0e463d2d33e24b745e7b42ba5715fc_r.jpg" data-original-token="v2-1a0e463d2d33e24b745e7b42ba5715fc"/></figure></p><p></p>
696652985,00f8d6e26185ae109666d97c11299a6e,科技调查君,https://api.zhihu.com/people/00f8d6e26185ae109666d97c11299a6e,people,分享是一种心境，学会分享就学会生活,AI<em>人工智能</em>+三色激光技术 Vidda发布2024旗舰电视、投影新品,article,https://api.zhihu.com/articles/696652985,四款新品全部配备可以360旋转的一体式云台底座，配合升级后的Vi-<em>AI智能</em>校正技术，校正速度提升约10倍。 Vidda AI Mini LED电视横空出世 <em>人工智能</em>助力音画 在本次新品发布会上，Vidda还发布了2024欧洲杯官方指定互联网电视,0,0,0,1715175731,1715175732,<p data-pid="P_dIkVna">5月8日，海信旗下年轻科技潮牌Vidda在北京正式发布新品AI电视和三色激光智能投影。“智者无畏”的主题展现了Vidda品牌对年轻人场景的全新探索和无惧无畏的精神面貌，而强大的产品阵容更是再一次诠释了质价比的定义。</p><p data-pid="xGCoAkP8">据Vidda副总经理郭琛介绍：2023年，Vidda电视在国内线上市场的量占有率近10%，牢牢占据行业前五位置，而在2024年一季度更是一举进入行业前三；在智能投影领域，Vidda 2023年销量同比提升266.84%，大幅跑赢行业。Vidda成为名副其实的消费电子领域增长最快的新兴品牌。</p><p class="ztext-empty-paragraph"><br/></p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-38f7e9e8be437166cfa36a64cdafad5b_b.jpg" data-caption="" data-size="normal" data-rawwidth="1149" data-rawheight="768" class="origin_image zh-lightbox-thumb" width="1149" data-original="https://pic4.zhimg.com/v2-38f7e9e8be437166cfa36a64cdafad5b_r.jpg" data-original-token="v2-e6f537c5949e50799395374562e5b30b"/></figure><p class="ztext-empty-paragraph"><br/></p><p data-pid="sn2MJIcJ"><b>三色激光投影再次大幅进化 Vidda旗舰持续跨代引领</b></p><p data-pid="2ViyNZVx">作为2024欧洲杯官方指定智能投影，本次发布会上亮相的Vidda C2系列四款新品属于Vidda开创的第三代三色激光投影，全部为4K超高清机型，技术能力和产品体验更加成熟，亮度、画质、智能全面提升。“高端投影看激光，专业激光选Vidda”，四款新品再次为高画质投影树立了标杆。</p><p class="ztext-empty-paragraph"><br/></p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-9ac81eacda69a820c35ba0b5fd8980f2_b.jpg" data-caption="" data-size="normal" data-rawwidth="1161" data-rawheight="774" class="origin_image zh-lightbox-thumb" width="1161" data-original="https://pic3.zhimg.com/v2-9ac81eacda69a820c35ba0b5fd8980f2_r.jpg" data-original-token="v2-a517a0fa60cae4ba8bfecd18912ba0be"/></figure><p class="ztext-empty-paragraph"><br/></p><p data-pid="z6UlCEY6">其中，跨代引领画质巅峰C2 Ultra和同代机皇C2 Pro配备了行业首创的0.9~1.5:1超广投射比超级光学变焦镜头，实测亮度高达3000流明和2600流明，画面对比度达2000:1，首发价格分别为11999元和9499元；全能旗舰C2S和质价比之王C2至臻版同样带来了2000流明和1700流明的同价位超高实测亮度，画面对比度达1700:1，首发价格分别为6999元和6399元。Vidda C2 Ultra、C2 Pro和C2S都载了全球顶级音响品牌JBL定制的10W×2高保真音响，使其不仅拥有行业顶级的画质，还拥有了世界级的音响表现。<br/>基于海信17年激光显示产研积累，超2500项激光显示相关专利，Vidda C2系列三激光投影可谓集大成之作。在色彩表现力上轻松实现了110% BT.2020的超高色域（151% DCI-P3）和△E＜0.9的超高色准，令其他现有显示技术望尘莫及。</p><p class="ztext-empty-paragraph"><br/></p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-025188e4ddd083d5fb03c6d32edf7446_b.jpg" data-caption="" data-size="normal" data-rawwidth="1152" data-rawheight="768" class="origin_image zh-lightbox-thumb" width="1152" data-original="https://pic3.zhimg.com/v2-025188e4ddd083d5fb03c6d32edf7446_r.jpg" data-original-token="v2-e868ebf5a483ef2fcda7c9509c469ed7"/></figure><p class="ztext-empty-paragraph"><br/></p><p data-pid="wl-EpEYt">作为全球三色智能激光投影的开创者，Vidda不仅在2022年首次将纯三色激光技术引入智能投影领域，更是与行业共同努力抵制亮度虚标乱象，并联合中国电子视像行业协会在2023年制定了全新的投影亮度标准。而Vidda 2024年发布的四款新品更是获得了国际权威机构德国莱茵颁发的全球唯一的“0%有害蓝光”、“广色域覆盖”和“极低色彩差异”智能投影验证声明，是目前市面上最为健康护眼的显示类产品。同时，四款产品均通过了IMAX ENHANCED和FilmMaker Mode权威画质认证（C2 Ultra还通过了HDR10+认证），让用户可以真正在家里体验IMAX同款技术。</p><p class="ztext-empty-paragraph"><br/></p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-7e042f7fda5fe623926775952b700d0a_b.jpg" data-caption="" data-size="normal" data-rawwidth="997" data-rawheight="997" class="origin_image zh-lightbox-thumb" width="997" data-original="https://pic3.zhimg.com/v2-7e042f7fda5fe623926775952b700d0a_r.jpg" data-original-token="v2-79ad843e9b5061882c902fef50b5fd40"/></figure><p class="ztext-empty-paragraph"><br/></p><p data-pid="N4OUKxZ-">据Vidda投影产品负责人姜龙介绍，Vidda C2 Ultra和C2 Pro行业首发搭载了全新的MCL 38激光器，因而不仅在亮度上领先行业，还带来了更好的能效比。其中C2 Ultra达到国标一级能效，是目前最为节能的高端智能投影。0.9~1.5:1超广投射比超级光学变焦镜头使得两款产品可以实现2米距离投出100英寸画面、3米距离投出150英寸画面，让影音发烧友们轻松实现拥有真正影院级巨幕的梦想。此外，C2 Ultra的底座中还集成了JBL定制的20W超大音腔独立低音单元，这也是目前行业唯一的设计。</p><p data-pid="F9VM-PX5">在智能硬件上，Vidda C2系列搭载新款64位四核A73芯片和4GB运行内存，可以流畅运行各类大屏智能应用，同时在扩展接口上也升级到了HDMI 2.1和USB 3.0标准，同时也保留了齐全的eARC、光纤数字音频和耳机等音频连接方式。同时,Vidda行业领先的远场语音功能和蓝牙/红外遥控也得到升级，语音识别更精准，智能助手更聪明。</p><p data-pid="TMmgw3HI">四款新品全部配备可以360°旋转的一体式云台底座，配合升级后的Vi-AI智能校正技术，校正速度提升约10倍。</p><p data-pid="1fl8vfeG"><b>Vidda AI Mini LED电视横空出世 人工智能助力音画</b></p><p data-pid="hpMbwDjW">在本次新品发布会上，Vidda还发布了2024欧洲杯官方指定互联网电视，全新的X Ultra系列AI Mini LED电视。新品覆盖65英寸、75英寸、85英寸、100英寸尺寸段，首发价格分别为4999元、6499元、8499元、15999元，除了带来同价位领先的1024、1260、1440、2304多背光分区，更实现了2500nits甚至2600nits（85英寸机型独享）的超高稳定峰值亮度。保证了即使在阳光充足的午后，光线直射客厅，也可以看清屏幕上的内容。有兴趣的朋友可以在各电商平台搜索“Vidda X Ulrta”详细了解，并领取新品体验惊喜礼。</p><p data-pid="N3cfym5B">全面的AI人工智能化是Vidda X Ultra系列新品最大的亮点。依托于C-Eval榜单电视行业排名第一的海信星海AI大模型，以及千PB级数据电视行业最大云底座聚好看Ju Cloud，Vidda X Ultra系列实现了观影、游戏、听唱等全场景的AI人工智能化。对于游戏玩家，Vidda X Ultra不仅支持4K 144Hz高刷和VRR、ALLM等功能以降低画面延迟，拥有Freesync Premium认证，同样也全面升级了AI游戏助理功能，让游戏体验更加畅快且智能。</p><p class="ztext-empty-paragraph"><br/></p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-988d244d95151f50c929a34d66559171_b.jpg" data-caption="" data-size="normal" data-rawwidth="1200" data-rawheight="799" class="origin_image zh-lightbox-thumb" width="1200" data-original="https://pic2.zhimg.com/v2-988d244d95151f50c929a34d66559171_r.jpg" data-original-token="v2-2208b0be85f81d91fbc31d6fc89de173"/></figure><p class="ztext-empty-paragraph"><br/></p><p data-pid="rWu23_0z">Vidda X Ultra系列全部标配独立低音炮，其中100英寸机型更是搭载9个发声单元，组建成2.1声道加环绕号角的音响方案。而对IMAX ENHANCED、Filmmaker Mode杜比视界IQ和杜比全景声的完整支持，使得拥有X Ultra系列的用户在家就可以享受专业级的独享视听体验。</p><p class="ztext-empty-paragraph"><br/></p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-53730811872c0d501a2408ed243fd4ec_b.jpg" data-caption="" data-size="normal" data-rawwidth="1176" data-rawheight="784" class="origin_image zh-lightbox-thumb" width="1176" data-original="https://pic1.zhimg.com/v2-53730811872c0d501a2408ed243fd4ec_r.jpg" data-original-token="v2-2837052f06d7ba9685da80cbe843fc52"/></figure><p class="ztext-empty-paragraph"><br/></p><p data-pid="3gQTpx-t">与旗舰级的音画质相匹配，Vidda X Ultra同样搭载了旗舰级的智能硬件，64位四核A73芯搭配4GB运行内存和64GB（100英寸机型为128GB）存储闪存，轻松应付各种类型大屏智能应用。无线连接升级至蓝牙5.4和WiFi 6，支持三大主流NAS协议的访问，支持蓝光原盘文件解码，支持远/近场语音和NFC一触投屏和双路投屏，大大增加了可玩性。同时，Vidda本次还发布了新款的自研AI美声麦克风V3和V7，具备AI自动美声功能，让所有人都可以大胆开口欢唱。</p><p class="ztext-empty-paragraph"><br/></p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-b0990147c33e642447fadf952307b3a2_b.jpg" data-caption="" data-size="normal" data-rawwidth="1064" data-rawheight="969" class="origin_image zh-lightbox-thumb" width="1064" data-original="https://pic3.zhimg.com/v2-b0990147c33e642447fadf952307b3a2_r.jpg" data-original-token="v2-a2c2d6a90516559a20a5090f7c4af7d8"/></figure><p class="ztext-empty-paragraph"><br/></p><p data-pid="Di0HgAZT">而在外观工艺上，Vidda X Ultra系列采用了金属批花拉丝前壳和金属底座，主体倾斜面设计带来更窄的视觉效果，低调有质感的设计语言与各种风格的居室环境都很搭。</p><p data-pid="oeqk32jL">本次Vidda发布的2024欧洲杯官方指定智能投影Vidda C2系列和2024欧洲杯官方指定互联网电视X Ultra系列，即日起在京东、天猫、抖音、拼多多等电商平台开启预约预售，感兴趣的朋友可前往Vidda官方旗舰店关注选购。</p>
695641297,95f2e2be27f19827ffe78b7d18877f0d,AIDD Pro,https://api.zhihu.com/people/95f2e2be27f19827ffe78b7d18877f0d,people,人工智能与药物研发领域发展探索者,使用量子增强<em>人工智能</em>设计新型 KRAS 抑制剂,article,https://api.zhihu.com/articles/695641297,Computer (Zapata AI) 与Insilico Medicine、多伦多大学和圣裘德儿童研究医院合作，在使用量子增强<em>人工智能</em> (<em>AI</em>) 设计新型 KRAS 抑制剂方面取得了重大进展,1,0,0,1715168668,1715168668,<p></p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkzNjIzMTU0Nw%3D%3D%26mid%3D2247544849%26idx%3D1%26sn%3D0ca4cf0675cfaf407327e90e23028c90%26chksm%3Dc2a3a705f5d42e13f83d0c388bdbfc0e4171b3a15d7a757ea605ce31a195a53936966e8fdbf6%26token%3D2073967997%26lang%3Dzh_CN%23rd" data-draft-node="block" data-draft-type="link-card" data-image="https://pic3.zhimg.com/v2-8ab600688757f63b2fa6af712a0e76f2_qhd.jpg" data-image-width="1280" data-image-height="545" class=" wrap external" target="_blank" rel="nofollow noreferrer">使用量子增强人工智能设计新型 KRAS 抑制剂</a><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-dec40adfff2f3a19d4580790d666d7f6_b.jpg" data-size="normal" data-rawwidth="1080" data-rawheight="589" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-dec40adfff2f3a19d4580790d666d7f6_r.jpg" data-original-token="v2-8a76d4db0c4330c7b4df071aafa913a9"/><figcaption>图片来源：iStock、Bartlomej Wroblewski</figcaption></figure><p data-pid="C7mAUgmr">Zapata Computer (Zapata AI) 与Insilico Medicine、多伦多大学和圣裘德儿童研究医院合作，在<b>使用量子增强人工智能 (AI) 设计新型 KRAS 抑制剂方面</b>取得了重大进展。该研究利用在 16 量子位 IBM 量子设备上运行的生成式 AI 模型产生了 100 万种潜在的候选药物。通过算法过滤和人工评估，这分子被缩减为15个，之后进行了合成和基于细胞的分析测试。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-3e7d835b4d93acfc0e70a1d3e98873a2_b.jpg" data-caption="" data-size="normal" data-rawwidth="800" data-rawheight="824" class="origin_image zh-lightbox-thumb" width="800" data-original="https://pic3.zhimg.com/v2-3e7d835b4d93acfc0e70a1d3e98873a2_r.jpg" data-original-token="v2-d2dbd1d023a9108fa453c3086081703e"/></figure><p data-pid="cZZXWqWY">图 1. 用于开发 KRAS 配体的量子-经典混合框架示意图。初始阶段主要是数据挖掘和制作用于模型训练的数据集。作者从文献中提取了经过实验验证的 650 种针对 KRAS 蛋白的抑制剂。通过应用 STONED-SELFIES 算法，得出每个已识别化合物的类似物，从而扩充了约 850,000 个化合物集合。使用针对 KRAS 蛋白的 REAL 配体库进行虚拟筛选，确定了前 250,000 个候选化合物，最终形成了一个包含 100 多万个分子的数据集，用于训练生成模型。完成模型训练后，作者将利用经典长短期记忆（Long Short-Term Memory ） LSTM 模型和量子回路天生机（Quantum Circuit Born Machines (QCBM) 作为基础生成框架，创建靶向 KRAS 的新分子。LSTM 网络处理包含配体化学结构的序列数据，而 QCBM 则根据 LSTM 生成样本的质量进行训练，创建复杂的高维概率分布。组合工作流程利用 Chemistry42 作为奖励函数，鼓励创造结构多样化和可合成的分子。</p><h2><b>KARS-难以开发的靶点</b></h2><p data-pid="DRbLR6NY"><b>KARS</b>是RAS 基因家族中的一员。由于RAS 基因家族经常在人类癌症中发生突变，导致直接靶向 RAS 蛋白的研究总是失败。最近有科研人员研发了直接靶向的KRAS G12C 抑制剂-sotorasib（AMG 510）和 adagrasib（MRTX849），改变了 KRAS  &#34;不可成药 &#34;的观点。然而，这两种抑制剂作为单药的临床疗效却并不持久。</p><h2><b>什么是量子回路天生机</b></h2><p data-pid="CeXrldft"><b>量子回路天生机（QCBM）是一种具有生成能力无监督的变分量子算法</b>。QCBM 与通常依赖经典神经网络的经典机器学习模型不同，它还具有叠加和纠缠的固有量子特性。与传统机器学习的方法相比qcbm的泛化能力，生成新的、有效的样本方面的能力更强，但量子信息处理在数据加载和可训练性等方面仍有许多不足。因此，作者取其精华去其糟粕，提出了一个新的量子-经典生成模型。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-ce9c78e6be7d8c318e5475201b6b5c88_b.jpg" data-caption="" data-size="normal" data-rawwidth="753" data-rawheight="663" class="origin_image zh-lightbox-thumb" width="753" data-original="https://pic1.zhimg.com/v2-ce9c78e6be7d8c318e5475201b6b5c88_r.jpg" data-original-token="v2-5330bf652f152b89ce118000b7b8b557"/></figure><p data-pid="NwFubwcm">图 2. 用于药物发现应用的量子增强生成模型。(A) 结合量子回路天生机（QCBM）和长短期记忆（LSTM）的混合模型。该模型使用来自量子硬件（quantum hardware）的先验样本进行迭代训练。(B) 将先验样本整合到 LSTM 架构中的方法。分子信息（SELFIES 编码）和量子数据通过加法或并集的方式进行合并。然后将得到的样本 X ′ (t) 输入 LSTM 单元。(C) 量子先验组件被描述为 QCBM，每个训练历时从量子硬件生成样本，并使用 Chemistry42 或局部滤波器计算的奖励值 P(x) = Softmax(R(x)) 进行训练。(D) 实验样本选择过程：从每个模型中抽取 100 万个化合物样本，包括经典样本（通过 vanilla LSTM）、量子样本（量子硬件上的 QCBM）和模拟样本（经典硬件上的量子模拟）。这些样本经过 Chemistry42 的评估，筛选出不适合药理学目的的化合物，并根据对接得分（PLI 分数）对剩余化合物进行排序。随后，选出 15 个新化合物进行合成。</p><h2><b>结论</b></h2><p data-pid="yXYpOpbl">作者介绍了一种旨在<b>发现特定分子靶标的新配体的量子-经典混合算法</b>。其方法巧妙地将作为先验分布的量子回路天生机（QCBM）与经典的长短期记忆（LSTM）模型结合在一起，并通过旨在促进类药物小分子生成的奖励函数来加强这种结合。作者通过对两组不同任务的计算评估，对进行了基准测试，结果显示作者的模型生成高质量分子的能力更高，但是与经典方法相比对接部分的得分略低。此外，作者还研究了量子比特数量对先验分布建模的影响，并观察到生成高质量分子的建模成功率与所涉及的量子比特数量大致呈线性相关。</p><p data-pid="QXuZOwKA">作者推出了一种量子-经典混合算法。虽然该算法使用的量子比特数量不多，并且没有任何纠错功能，连接性也有限，但是目前的该算法的性能已经超越了传统算法，这预示着<b>更先进的量子计算机和更好的量子-经典算法在未来的药物发现中有着巨大的潜力</b>。随着量子比特数量的增加、保真度的提高、纠错能力的增强以及连接性的增强，<b>量子计算</b>在药物发现中的应用前景会逐渐成为计算和实验科学的新风潮。</p><p data-pid="ZgW8HF9l">参考资料：Vakili M G, Gorgulla C, Nigam A K, et al. Quantum Computing-Enhanced Algorithm Unveils Novel Inhibitors for KRAS[J]. arXiv preprint arXiv:2402.08210, 2024.</p><h2><b>版权信息</b></h2><p data-pid="Ri8JyPpS"><b>本文系AIDD Pro接受的外部投稿，文中所述观点仅代表作者本人观点，不代表AIDD Pro平台，如您发现发布内容有任何版权侵扰或者其他信息错误解读，请及时联系AIDD Pro (请添加微信号sixiali_fox59)进行删改处理。</b></p><p data-pid="ds_pewqw"><b>本文为原创内容，未经授权禁止转载，授权后转载亦需注明出处。有问题可发邮件至sixiali@stonewise.cn</b></p>
696396356,47767cbcbfe7a85006b1a4d45202ca08,西湖大学<em>人工智能</em>,https://api.zhihu.com/people/47767cbcbfe7a85006b1a4d45202ca08,people,Westlake AI 官方发布,面向全球本硕学生，西湖大学<em>人工智能</em>暑期公开课开启报名,article,https://api.zhihu.com/articles/696396356,机器学习、深度学习、数据科学； 2. <em>AI</em> 核心应用：计算机视觉、语音语言处理、机器人、数据挖掘； 3. <em>AI</em> for Science：AI 生命科学、<em>AI</em> 生物医学、AI 学科交叉。 *报名通道现已开启,13,1,15,1715071579,1715071579,<p data-pid="da7Urdyw">与AI科学家面对面，你最想问什么？</p><p data-pid="hzEj_AU5">是复杂算法背后的秘密，还是未来技术的趋势？是人工智能如何改变世界，还是AI职业发展策略？</p><p data-pid="Lq_OxW8Z"><b>2024年7月28日至8月11日</b>，西湖大学工学院将开设<b>为期2周</b>的人工智能暑期公开课，<b>12位</b>人工智能与数据科学领域的资深教授将来到西湖大学云谷校区，<b>邀请本科生、硕士生</b>共同探讨人工智能发展的最前沿。</p><p data-pid="UVZT66IK">听他们讲讲，当今世界上最先进的AI大模型、类人学习，以及AI在医疗、金融、教育等各个领域的应用；还有机会走进西湖大学人工智能相关实验室或产业转化基地，感受AI在多个领域的萌芽和发展，<b>实地了解一项科技成果从“实验室”走向“应用场”的全过程。</b></p><p data-pid="kNTiYpIO">西湖大学人工智能暑期公开课主要涵盖的研究方向包括：</p><p data-pid="LDqXeC70">1. <b>AI 基础研究：</b>机器学习、深度学习、数据科学；</p><p data-pid="GqCAIugn">2. <b>AI 核心应用：</b>计算机视觉、语音语言处理、机器人、数据挖掘；</p><p data-pid="Ai-E2bFy">3. <b>AI for Science：</b>AI 生命科学、AI 生物医学、AI 学科交叉。</p><p data-pid="qkTJB9tA"><i><b>*报名通道现已开启，具体报名方式详见文末</b></i></p><h3><b>人工智能暑期公开课</b></h3><h3><b>首批12位导师介绍</b></h3><p data-pid="VM6FhG1i"><b>人工智能与数据科学领域是西湖大学工学院重点建设的方向。</b>工学院AI分支目前已有<b>20位PI（特聘研究员、博导）</b>，他们来自世界知名的实验室和科研机构，除了组建实验室进行AI相关研究外，也承担本科生、博士生的教学任务。2024年西湖大学人工智能暑期公开课，首批12位导师阵容正式发布。首发阵容包含<b>西湖大学AI方向2位讲席教授，和来自国内外高校的10位资深教授</b>，他们将为学生们带来AI 基础研究、AI 核心应用、AI for Science等方向的前沿新知。</p><p data-pid="KzyqdIyQ"><i><b>*以下是首批12位导师介绍</b>（按姓氏拼音排序）</i></p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-1da32861d0893519190d03c2f607b164_b.jpg" data-caption="" data-size="normal" data-rawwidth="768" data-rawheight="768" class="origin_image zh-lightbox-thumb" width="768" data-original="https://pic1.zhimg.com/v2-1da32861d0893519190d03c2f607b164_r.jpg" data-original-token="v2-9e530603dce5e44e0e6332728cc9e571"/></figure><p data-pid="1pGz7hka"><b>程涛教授</b></p><p data-pid="-FdsLp3b"><b>伦敦大学学院</b></p><p data-pid="t8Um-3jY"><b>程涛教授是伦敦大学学院地理信息学教授，博士生导师，图灵研究所研究员，大数据分析SpaceTimeLab的创始人和主任。</b>她的研究兴趣包括人工智能和大数据、网络复杂性、城市分析（建模、预测、聚类、可视化和模拟），及其在交通、商业、健康、社交以及犯罪和自然灾害预防等方面的应用。她在英国和欧盟获得了2500多万英镑的研究经费，与英国的多个政府机构和企业有深度合作。她发表了300多篇研究论文，并获得了众多国际最佳论文奖。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-0c8a130bb03c10b9e96f729fa5af0794_b.jpg" data-caption="" data-size="normal" data-rawwidth="400" data-rawheight="400" class="content_image" width="400" data-original-token="v2-c5f7d4fe16b1db0dc9f8d8ed8f651e1a"/></figure><p data-pid="2iNoFmiZ"><b>何瑜岚教授</b></p><p data-pid="vcnL8Pb6"><b>伦敦国王学院</b></p><p data-pid="grLdTsC7"><b>何瑜岚为英国伦敦国王学院（King’s College London）计算机系教授，2021年入选英国AI人才计划，获Turing AI Fellow称号。</b>何瑜岚长期从事自然语言处理领域的研究工作，在这些领域中发表相关论文超过200篇。研究方向包括机器阅读理解、模型可解释性和可信人工智能以及NLP在医疗、金融和教育领域里的应用。她的研究获得了多项奖项，包括SWSA十年奖及CIKM时间检验奖。受邀担任自然语言处理领域的国际顶级会议EMNLP2020的程序委员会主席、AACL2022大会主席及多个国际顶级会议的（资深）区域主席。何瑜岚主持了24项科研项目，总价值超过600万英镑，资助方包括英国工程及物理科学基金、英国创新科技局、英国皇家工程学院，欧盟地平线2020及欧盟第七框架。曾担任华为欧洲区自然语言处理领域顾问，目前担任伦敦证券交易所集团顾问，对大规模语言模型相关业务提供建议。2020年入选清华大学-中国工程院知识智能联合研究中心、清华大学人工智能研究院与北京智源人工智能研究院发布的人工智能全球女性Top100榜单，并获得AI 2020最具影响力学者提名奖。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-949a9ccd6330501074b4b6ca44180528_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1080" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-949a9ccd6330501074b4b6ca44180528_r.jpg" data-original-token="v2-afbb822b8f4d5ffaa777a90367e2422c"/></figure><p data-pid="bIddqSoE"><b>金耀初教授</b></p><p data-pid="ftKzJPZy"><b>西湖大学</b></p><p data-pid="3Y-FtAG7"><b>金耀初，西湖大学人工智能讲席教授，欧洲科学院院士、国际电气和电子工程师协会会士（IEEE Fellow）。</b>曾任芬兰科学院与芬兰国家创新局“芬兰杰出教授”、德国联邦教育与研究部“洪堡人工智能教席教授”。金耀初教授已出版专著5部，在多个IEEE汇刊及CVPR、NeurIPS、ICLR及ACM MM等学术会议发表论文500余篇，获美国、欧盟和日本专利9项。多次获“IEEE进化计算汇刊优秀论文奖”及“IEEE 计算智能杂志优秀论文奖”。曾任《IEEE认知与发育系统汇刊》主编，IEEE计算智能学会副理事长，两次担任IEEE 杰出演讲人。任2016 IEEE 计算智能系列研讨会总主席、2020 IEEE 进化计算大会主席等。长期从事人工智能与计算智能的理论、算法和工程应用研究，特别是数据驱动的优化、多目标优化，演化机器学习，安全与隐私保护的机器学习与优化、图神经网络组合优化、演化发育通用人工智能及形态发育自组织机器人等。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-7aa8e3088e0f784a2eb52fae698be082_b.jpg" data-caption="" data-size="normal" data-rawwidth="675" data-rawheight="675" class="origin_image zh-lightbox-thumb" width="675" data-original="https://pic3.zhimg.com/v2-7aa8e3088e0f784a2eb52fae698be082_r.jpg" data-original-token="v2-2a972bc9fb5017bb570923aace4d09ff"/></figure><p data-pid="sX8JIZoP"><b>Josef Kittler教授</b></p><p data-pid="j_6T0bOI"><b>萨里大学</b></p><p data-pid="w5DLIj-2"><b>Josef Kittler教授为英国皇家工程院院士、国际模式识别协会前主席，英国萨里大学计算机与电子工程学院杰出教授。</b>Josef Kittler教授是模式识别研究领域享有盛誉的国际顶级学者，研究领域主要包括模式识别、生物特征识别、机器学习和人工智能。其合著著作《模式识别：一种统计学方法》是模式识别研究领域的经典著作之一。迄今为止，教授共发表论文1000余篇，学术引用近七万次，承担了数十个英国和欧盟政府资助的研究课题。Josef Kittler教授还于1986年创立了英国萨里大学计算机视觉、语音和信号处理中心（CVSSP），该中心是目前英国最大的计算机视觉和人工智能研究中心，在计算机视觉研究领域名列英国第一。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-8eff47ca1c2cfb16971883ac7d391f24_b.jpg" data-caption="" data-size="normal" data-rawwidth="1073" data-rawheight="1073" class="origin_image zh-lightbox-thumb" width="1073" data-original="https://pic1.zhimg.com/v2-8eff47ca1c2cfb16971883ac7d391f24_r.jpg" data-original-token="v2-5c276d05697584750919fdbb552aeb64"/></figure><p data-pid="op6Sv1el"><b>李子青教授</b></p><p data-pid="Dnq-P1Ge"><b>西湖大学</b></p><p data-pid="K7nz3oe8"><b>李子青（Stan Z. Li, IEEE Fellow），西湖大学人工智能讲席教授，曾任微软亚洲研究院lead researcher、中科院自动化所模式识别国家重点实验室资深研究员。</b>发表论文500余篇，著作10部，Google Scholar引用65000余次，World Scientist and University Rankings 2024 计算机学科中国区排名第2。他领导开发了世界上第一个实时人脸识别系统，设计研发了多个国家级人脸识别系统，并落地实施应用。当前负责实施科技部“新一代人工智能”重大项目2项、国家自然科学基金区域重点项目（AI+生命科学）1项。实验室研究包括两大方向：AI基础研究，包括图/序列/多模态表征学习、自监督学习、生成模型、预训练方法；AI for Science研究，包括AI+生命科学、AI+合成生物学等。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-8e7122ef6063cac6ad5ae7def8ffa8a6_b.jpg" data-caption="" data-size="normal" data-rawwidth="880" data-rawheight="880" class="origin_image zh-lightbox-thumb" width="880" data-original="https://pic3.zhimg.com/v2-8e7122ef6063cac6ad5ae7def8ffa8a6_r.jpg" data-original-token="v2-37c2ab32c18ee0dd429de9e35af98aa4"/></figure><p data-pid="QHxdhWXv"><b>刘兵教授</b></p><p data-pid="kWv0GsT6"><b>伊利诺伊大学芝加哥分校</b></p><p data-pid="A5Z4VEEb"><b>刘兵，伊利诺伊大学芝加哥分校杰出教授，</b>于爱丁堡大学获得人工智能博士学位。ACM Fellow，IEEE Fellow，主要从事语义分析、观点挖掘、数据挖掘、机器学习以及自然语言处理等方面的研究，<b>是语义分析、观点挖掘研究领域的开创者之一。</b>刘兵教授有两篇论文在KDD会议中获得“10-year test-of-time”奖项，其工作曾被纽约时报头版报道。刘兵教授还担任ACM SIGKDD Chair，DMKD Action Editor，TWEB、KAIS等期刊的Associate Editor。他曾在2013-2017年担任ACM SIGKDD主席，并担任众多重要数据挖掘会议的项目主席，也是2018年ACM SIGKDD创新奖得主。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-2e05cb6cec10150062338b762b3fb966_b.jpg" data-caption="" data-size="normal" data-rawwidth="432" data-rawheight="432" class="origin_image zh-lightbox-thumb" width="432" data-original="https://pic3.zhimg.com/v2-2e05cb6cec10150062338b762b3fb966_r.jpg" data-original-token="v2-b920480a6cf1f5bacf0808d6766ad4ab"/></figure><p data-pid="mcxUXvPz"><b>Marios M. Polycarpou教授</b></p><p data-pid="b1aLboBz"><b>塞浦路斯大学</b></p><p data-pid="B3eqEmm9"><b>Marios M. Polycarpou教授</b>为欧洲科学院院士、IEEE Fellow、IFAC Fellow、塞浦路斯科学文学和艺术学院院士，<b>现担任塞浦路斯大学KIOS智能系统与网络研究中心主任</b>，是塞浦路斯大学电气与计算机工程系创始成员，英国帝国理工学院荣誉教授，《Proceedings of the IEEE》《Annual Reviews in Control》《Foundations and Trends in Systems and Control》编辑委员会成员。他的教学和研究领域包括智能系统与网络，自适应与协同控制系统，计算智能，故障诊断与分布式处理等。发表超过300篇学术期刊，专辑和学术会议论文，并与他人合作撰写专著7本。他是IEEE和IFAC的会士，曾担任IEEE计算智能学会主席以及IEEE Transactions on Neural Networks and Learning Systems杂志主编，获2016年IEEE神经网络先驱奖，先后参加了60多个欧洲和美国的专业机构和工业的研究项目，包括欧洲研究理事会（ERC）高级拨款、ERC协同拨款和欧盟团队计划。</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-f655bf16788f60ef180a37bf270cc727_b.jpg" data-caption="" data-size="normal" data-rawwidth="648" data-rawheight="647" class="origin_image zh-lightbox-thumb" width="648" data-original="https://pic4.zhimg.com/v2-f655bf16788f60ef180a37bf270cc727_r.jpg" data-original-token="v2-9c703f349dc758cb3ce2604eefad018c"/></figure><p data-pid="cT0JsDNP"><b>申强教授</b></p><p data-pid="zgYf4kyP"><b>亚伯大学</b></p><p data-pid="2txzflHr"><b>申强教授是英国皇家工程院院士，威尔士科学院院士、理事会成员，英国亚伯大学副校长兼商学与物理科学学部主任。</b>曾连续两次被任命为英国高校及研究院卓越研究评估框架（REF2014：2008-2014 和 REF2021：2014-2021）的计算机科学和信息学评委会成员。在众多国际会议任主席或发表主题演讲，并长期担任英国计算智能指导委员会主席。撰写两部研究专著和450多篇论文，是2024 IEEE 模糊系统先驱奖获得者。申强教授的研究包括：计算智能、不确定性学习与推理、模式识别、数据建模与分析及其在智能决策支持中的应用。</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-e4bed0c8373698701b216206d91deeb9_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1138" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-e4bed0c8373698701b216206d91deeb9_r.jpg" data-original-token="v2-90229dd13b3c893f03b42e2d50099ac0"/></figure><p data-pid="WDM0oaXN"><b>沈春华教授</b></p><p data-pid="eUlek-cK"><b>浙江大学</b></p><p data-pid="D1xthpxO"><b>沈春华教授</b>，本科毕业于南京大学、后在阿德莱德大学获得博士学位。机器视觉领军学者。<b>现任浙江大学计算机学院、计算机辅助设计与图形学国家重点实验室求是讲席教授。</b>2012年，沈春华获得澳大利亚研究委员会的未来学者称号。此外，他担任澳大利亚研究委员会机器人视觉卓越中心的科研负责人。2020年，沈春华获得澳大利亚科研终身成就奖，是工程与计算机类奖项的5名获选人之一。据计算机排名网站 CSRanking 显示，沈春华是过去10年间在计算机视觉方向3大顶级会议发表论文最多的在澳学者。沈春华教授主要研究领域为目标检测、图像分割等方向。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-4a0db428df1c40f934f83ea7ccaa4fd6_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1161" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-4a0db428df1c40f934f83ea7ccaa4fd6_r.jpg" data-original-token="v2-f959a371e86d7d01f9516e86fdaddd07"/></figure><p data-pid="uPFp4WT3"><b>杨先一教授</b></p><p data-pid="nJ5FarJg"><b>圭尔夫大学</b></p><p data-pid="H4rW6mPf"><b>杨先一教授</b>于1987年毕业于北京大学技术物理系，1990年获中国科学院生物物理硕士学位；1996年12月获美国休斯敦大学电子与计算机工程第二个硕士学位；1999年6月获加拿大阿尔伯塔大学电机与计算机工程博士学位。<b>现任加拿大圭尔夫大学高级机器人与智能系统实验室主任。</b>杨先一教授成功地提出了一个“受生物启发的神经网络系统（Biologically Inspired Neural Network Framework）”，该系统可用于各种机器人系统的实时环境感知、路径规划、目标跟踪和控制，并发表了一系列相关研究论文。他被认为是“将受生物启发的方法用于机器人学与控制系统”的先驱者之一。杨教授的研究方向包括机器人、人工智能、传感器和信号处理、多传感器融合、无线传感器网络、智能控制和计算神经科学。</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-81eb482d4159df9133721988ea54b8f3_b.jpg" data-caption="" data-size="normal" data-rawwidth="682" data-rawheight="682" class="origin_image zh-lightbox-thumb" width="682" data-original="https://pic4.zhimg.com/v2-81eb482d4159df9133721988ea54b8f3_r.jpg" data-original-token="v2-21e0eb8fff206c4b5cbd8b6e04dfd16b"/></figure><p data-pid="hVTO-3EE"><b>张孟杰教授</b></p><p data-pid="hrjvy5Bb"><b>惠灵顿维多利亚大学</b></p><p data-pid="uE2YYY4R"><b>张孟杰教授是新西兰皇家科学院院士（Fellow of RSNZ），IEEE会士/院士（Fellow of IEEE），IEEE杰出讲席教授（IEEE Distinguished Lecturer）。</b>现任新西兰惠灵顿维多利亚大学学术委员会委员，科学研究委员会成员，奖学金评定委员会委员；惠灵顿维多利亚大学工学部副部长兼工程与主计算机学院科学研究委员会主席，进化计算研究中心主任，计算机科学首席教授，博士生导师；惠灵顿维多利亚大学人工智能、机器学习、大数据及进化计算学科及科学研究牵头人。主要研究领域为人工智能、机器学习与大数据，尤其是在进化计算与学习（遗传编程、粒子群以及学习分类系统）、特征提取、选择、构造和变换及高维降维、计算机视觉与图形处理、作业车间调度和资源分配，多目标优化，数据不平衡分类和缺失数据分类，自动进化深度学习和迁移学习。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-f5a7efddba47c72c2801d9445c1d2f64_b.jpg" data-caption="" data-size="normal" data-rawwidth="540" data-rawheight="540" class="origin_image zh-lightbox-thumb" width="540" data-original="https://pic1.zhimg.com/v2-f5a7efddba47c72c2801d9445c1d2f64_r.jpg" data-original-token="v2-2bed2acfbd5f12db74fcf8486e6be00e"/></figure><p data-pid="ap2c7JEh"><b>张峥教授</b></p><p data-pid="d1LYldHd"><b>亚马逊云科技上海人工智能研究院</b></p><p data-pid="u9V8sFiw"><b>张峥教授是亚马逊云科技资深首席科学家、亚马逊云科技上海人工智能研究院院长</b>，本科毕业于复旦大学电子工程系，后获得美国伊利诺伊大学厄巴纳-香槟分校（UIUC）博士学位。他曾任上海纽约大学计算机终身教授，研究领域为深度学习、人工智能、高性能大容量计算和存储系统，多次获国际学术会议论文奖，是开源深度学习平台MXNet和DGL的共同创始人和顾问。张峥教授在大规模分布式计算理论与实践、及其与机器学习的交叉领域被公认为经验丰富的世界级专家。</p><h3><b>报名通道现已正式开启</b></h3><h3><b>面向全球遴选优秀学生</b></h3><p data-pid="7CiRuGg1"><b>公开课时间</b></p><p data-pid="iBCkUQpM">2024年7月28日至8月11日</p><p data-pid="1kVIqp8f"><b>申请截止时间</b></p><p data-pid="-yEISz4Y">2024年6月15日17时整</p><p data-pid="4fws-uti"><b>申请方式</b></p><p data-pid="hM4g0hSZ">访问下方链接，申请参加西湖大学人工智能暑期公开课。</p><p data-pid="d8BfxV5X"><u><a href="https://link.zhihu.com/?target=https%3A//www.wjx.top/vm/ryK8VrQ.aspx%23" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://www.</span><span class="visible">wjx.top/vm/ryK8VrQ.aspx</span><span class="invisible">#</span></a></u></p><p data-pid="Fxdcm1RY"><b>审核及录取</b></p><p data-pid="dH9BXN92">工学院资格审查小组组织评审，根据报名情况<b>择优录取50人</b>。遴选结果将于2024年6月28日前通过邮件另行通知，电子邮箱、手机号码等本人联系方式请保持通讯通畅。</p><p data-pid="qDbNy2KV"><b>费用说明</b></p><p data-pid="IxMUO-n3">本次人工智能暑期公开课免收学费。针对报名成功并通过评审的申请者，主办方将承担其城市间交通费用、住宿费及餐食。主办方将为完成2周全部公开课课程的学员发放证书。</p><p data-pid="v-TGbRyi"><b>联系方式</b></p><p data-pid="_bOAeQ3v">电话：0571-87381209</p><p data-pid="oEqVdGSB">邮箱：summercamp_se@westlake.edu.cn</p><p data-pid="VjHFG93c"><b><i>*公开课详细课程内容及日程安排</i></b></p><p data-pid="BjmDP89i"><b><i>敬请关注西湖大学人工智能知乎号的后续通知</i></b></p>
696231765,b5379f1a6ed18db1d60c50fdf71b469b,DeepTech深科技,https://api.zhihu.com/people/b5379f1a6ed18db1d60c50fdf71b469b,people,科学、技术、产业。,上海交大团队研发通用<em>人工智能</em>，解决传统蛋白质工程难题,article,https://api.zhihu.com/articles/696231765,在一定程度上打破了传统方法面临的瓶颈，利用 AI 来设计和改造蛋白质，逐渐成为该领域的大势所趋。 自主研发蛋白质设计通用<em>人工智能</em>，实现从序列到功能的精准蛋白预测 据介绍，在 AI 蛋白质设计领域,5,0,0,1714997481,1714997488,<p data-pid="PddJkIBZ">“作为一名基础科研人员，当我第一次看到我们研发的蛋白质工程通用人工智能技术，实现面向功能的蛋白序列设计，并被湿实验验证成功之时，心中涌起的激动是无与伦比的。”上海交通大学自然科学研究院&amp;物理与天文学院&amp;药学院特聘教授洪亮表示。</p><p class="ztext-empty-paragraph"><br/></p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-110f11abb5a2d13a20a68ba550fe2c27_b.jpg" data-size="normal" data-rawwidth="407" data-rawheight="535" class="content_image" width="407" data-original-token="v2-110f11abb5a2d13a20a68ba550fe2c27"/><figcaption>图 | 洪亮（来源：洪亮）</figcaption></figure><p class="ztext-empty-paragraph"><br/></p><p data-pid="K22qHVZZ">他进一步解释道，这意味着以前需要靠专家经验和大量实验试错的蛋白质工程，现在可以通过通用人工智能进行定向设计，从而数倍乃至数十倍地减少时间和经济成本。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="-EiuaJoN">此外，由于该模型具有通用性，对各领域都适用，决定了它将大大加速我国生物制造业、合成生物学、生物医药等领域的发展，帮助我国企业与国际头部公司进行良性互动与竞争。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="YP5tw3rt">相关论文以《蛋白质工程与轻量级图去噪神经网络》（Protein Engineering with Lightweight Graph Denoising Neural Networks）为题发表在 <i>Journal of Chemical Information and Modeling</i> 上[1]。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="IJNnYKlS">上海交通大学自然科学研究院助理研究员周冰心博士为第一作者，洪亮教授担任通讯作者。</p><p class="ztext-empty-paragraph"><br/></p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-7300331f0df7944041ad5608912c5959_b.jpg" data-size="normal" data-rawwidth="1080" data-rawheight="252" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-7300331f0df7944041ad5608912c5959_r.jpg" data-original-token="v2-7300331f0df7944041ad5608912c5959"/><figcaption>图 | 相关论文（来源：Journal of Chemical Information and Modeling）</figcaption></figure><p class="ztext-empty-paragraph"><br/></p><p data-pid="tymndlrx">现如今，洪亮和团队开发的蛋白质设计通用人工智能 AccelProtein™，通过 AI+ 计算的“干实验”与高效的“湿实验”协同闭环迭代，解决了传统蛋白质工程中研发时间长、成本高、上位组合差等核心问题，为体外检测、合成生物学等领域提供了数十款性能优异的蛋白质产品。</p><p class="ztext-empty-paragraph"><br/></p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-964732f6d3489bf0d98e30384457ec3a_b.jpg" data-caption="" data-size="normal" data-rawwidth="750" data-rawheight="114" class="origin_image zh-lightbox-thumb" width="750" data-original="https://pic3.zhimg.com/v2-964732f6d3489bf0d98e30384457ec3a_r.jpg" data-original-token="v2-964732f6d3489bf0d98e30384457ec3a"/></figure><p data-pid="_JTWmrmE"><b>利用通用人工智能设计蛋白质，已成为蛋白质工程领域的大势所趋</b></p><p class="ztext-empty-paragraph"><br/></p><p data-pid="4KLvGYa_">众所周知，蛋白质是生命系统的基础，在细胞、组织和器官中扮演着重要角色。除了它所拥有的生物学意义，蛋白质对于众多行业应用来说也至关重要，具有广泛的市场价值。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="NIVmwQJw">例如，在生物医学领域，可以作为药物靶点和治疗剂；在化学工程领域，能充当各种反应的关键催化剂。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="v3nYUN9F">不过，自然界的蛋白质，通常需要经过工程改造，提高它的活性、热稳定性、对极端 PH 环境和恶劣溶剂的耐受性等多种指标之后，才能在各类工业应用中获得应用。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="7amvq90y">而利用传统蛋白质设计需要经历长达数年的实验研究，不仅耗时耗力、成本较大，也愈发不能满足许多工业应用中重要蛋白质的改造要求。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="Qv6l2Qcw">近年来，深度学习技术的发展，在一定程度上打破了传统方法面临的瓶颈，利用 AI 来设计和改造蛋白质，逐渐成为该领域的大势所趋。</p><p class="ztext-empty-paragraph"><br/></p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-23da758958472f6409049afac819975b_b.jpg" data-caption="" data-size="normal" data-rawwidth="750" data-rawheight="114" class="origin_image zh-lightbox-thumb" width="750" data-original="https://pic4.zhimg.com/v2-23da758958472f6409049afac819975b_r.jpg" data-original-token="v2-23da758958472f6409049afac819975b"/></figure><p data-pid="zxuCkyb_"><b>自主研发蛋白质设计通用人工智能，实现从序列到功能的精准蛋白预测</b></p><p class="ztext-empty-paragraph"><br/></p><p data-pid="Xnuq7fPI">据介绍，在 AI 蛋白质设计领域，洪亮已有多年研究经验。他本科和硕士分别毕业于中国科学技术大学和香港中文大学的物理系，博士时期在美国阿克伦大学高分子科学系从事蛋白质生物物理方面的机制研究。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="Y3w8kT_5">在美国橡树岭国家实验室完成博士后研究后，他来到上海交通大学，通过将实验和计算生物学方法进行结合的方式，继续对蛋白质的性能进行研究。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="fTNe6PE8">“其实这些研究都属于‘后解释’的范畴。换言之就是，对蛋白质的一些物理机制进行解释，比如它的运动形态和各种热力学参数如何影响其功能的发挥。”洪亮解释说。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="8NnBdilT">2020 年，AlphaFold 的问世为洪亮开启 AI 蛋白质设计研究打造了一个契机。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="vQcrEvJw">“用户只需向 AlphaFold 输入蛋白质序列，就能得到准确的结构预测，这对于整个分子生物学领域来说非常震撼。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="F9Ncr2Wk">但 AlphaFold 只解决了从序列到结构的问题，没有解决结构到功能的问题，我们想做一套打通结构到功能的通用人工智能，彻底打破传统蛋白质工程方法的禁锢。”他说。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="1AxK1Iwo">因此，他开始带领团队做 AI 蛋白质设计方面的研究，并在 2021 年开发了一套基于预训练的蛋白质设计的通用人工智能 AccelProtein™ ——与 AlphaFold 预测结构不同，AccelProtein™ 开创性地实现了从序列直达功能的精准蛋白质设计。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="N8_0nPWV">具体来说，该课题组通过预训练方法，让 AccelProtein™ 学习自然界已知的所有蛋白质序列和结构特征，并探索与理解自然界中蛋白质序列与功能的映射规律，从而开发出一套能够高效地设计出稳定性好、活性高、功能性强的 AI 蛋白质设计通用大模型。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="5i79MMYr">那么，该模型如何实现精准的蛋白质设计？</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="HCufi5Nw">据洪亮介绍，自然界已知的具有完整氨基酸序列的蛋白质有几亿条，这些蛋白质的氨基酸序列以存在即合理的方式排列着。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="FI6NGipn">在掌握这些序列以后，该团队采用双重任务学习方法：一方面，帮助大模型在经过预训练学习以后，掌握满足蛋白质序列排布的语言规则，另一方面，通过所构建的亿量级蛋白质标签数据库，为蛋白质打上标签，进一步提升模型精度，从而提供精准、高效地蛋白质设计，大大降低试错成本。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="Te2N5Fr1">和同类通用人工智能模型相比，AccelProtein™ 主要具备如下优势。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="NcuJwU7X">其一，架构优势。采用几何深度学习方法对模型架构进行简化，能在保证模型精度的同时降低模型参数，便于进行大规模预训练和推理。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="x6arN0YB">其二，策略优势。利用小样本乃至零样本学习方法，提高大模型的工程泛化能力，帮助它在仅有少数湿实验数据的情况下实现蛋白质性能优化，极大地提高了蛋白质设计的效率——以往需要 2~5 年才能完成的项目，在 AccelProtein™ 的支持下只需要 2~6 个月即可完成。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="fwgIwDuj">其三，数据优势。通过与国内多家科研院所和企业的合作，获得了丰富全面的高精度蛋白质序列数据，尤其是一些高热、低温或强酸强碱环境下的数据。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="Ba1grnuC">此外，该课题组还开发了其他几种 AI 蛋白质通用大模型，并取得了可与 Google、Meta 等国际团队推出的同类成果相媲美的成绩。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="KLFiqDIV">根据美国哈佛大学医学院创立的蛋白质突变性质预测榜单 ProteinGym，洪亮团队提出的大模型夺得非检索方法排名第一的桂冠，并在总榜前十名的排名中占据一半席位。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="oxyjXN1F">其中，预测真核蛋白的大模型排名第一，预测原核蛋白的大模型排名第二，预测人类蛋白的大模型排名第三[2]。</p><p class="ztext-empty-paragraph"><br/></p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-b2fe4f38610963ded2900ccd7bd80678_b.jpg" data-size="normal" data-rawwidth="1080" data-rawheight="465" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-b2fe4f38610963ded2900ccd7bd80678_r.jpg" data-original-token="v2-b2fe4f38610963ded2900ccd7bd80678"/><figcaption>（来源：ProteinGym 榜单）</figcaption></figure><p class="ztext-empty-paragraph"><br/></p><p data-pid="z6I_7PPz">如上所说，在整个蛋白质设计过程中，通用人工智能可在不需要或仅有少数湿实验数据的条件下，完成对蛋白质改造的赋能。这是否意味着，生物实验在其中已经没有发挥作用的空间？</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="fSmUNbLS">对此，洪亮持否定看法。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="HVzFq1LW">他认为，首先，AI 在优化特定蛋白时，还需要湿实验来指导和调整方向。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="jHl7q42z">其次，生物学家也能够通过湿实验提出更多典型的科学问题，便于大模型团队基于这些问题开发定制化的大模型，从而实现批量的蛋白质设计。</p><p class="ztext-empty-paragraph"><br/></p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-ad7a20bc1f828eaf58f6caafd877221e_b.jpg" data-caption="" data-size="normal" data-rawwidth="750" data-rawheight="114" class="origin_image zh-lightbox-thumb" width="750" data-original="https://pic3.zhimg.com/v2-ad7a20bc1f828eaf58f6caafd877221e_r.jpg" data-original-token="v2-ad7a20bc1f828eaf58f6caafd877221e"/></figure><p data-pid="MwfI0Aq3"><b>创办 AI 蛋白质设计公司，已完成十余项蛋白质产品交付</b></p><p class="ztext-empty-paragraph"><br/></p><p data-pid="Xl-1vC_J">正是基于在 AI 蛋白质设计领域取得的成果，洪亮于 2021 年创办了上海天鹜科技有限公司。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="V480G7O7">后者已经在不到三年时间里，完成了十余款蛋白质设计项目的成果交付，并已获得数千万元 Pre-A 轮融资，投资机构包括耀途资本、金沙江资本等。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="7haZVZgq">据了解，目前该公司的服务范围已拓展至创新药、体外诊断、合成生物学等多个行业领域。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="a7KiCxi6">当下及未来，该课题组也在尝试拓展与更多科研院所和企业之间的合作，希望能在蛋白质工程这一赛道，打出全国最好、世界最优的标志。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="r6xLHVB0">在洪亮看来，虽然中国的生物制药行业目前已然具备强大的实力，但在全球整个产品链条中的利润比仍然较低。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="WaDvelyp">原因在于，缺乏良好的设计上游产品的能力，以至于在短时间内无法实现“破局”。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="uXmZkGD8">“毕竟国际企业所拥有的设计能力，是在过去一百年来经过大量的科研探索和实验数据积累，以及数不清的人才积淀的基础上才产生的。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="vh7rjNlj">但如今有了蛋白质通用人工智能，我们就可以不走国际企业的这条发展道路，直接利用 AI 来实现‘换道超车’。”洪亮表示。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="t21GBS4G">可以想见，一旦这条横穿跑道的道路被走通，我国就能在合成生物学和生物医药领域，和国际企业展开一场全新的竞争。</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="Kd6CJ5Pd">参考资料：</p><p data-pid="oDodmeVw">1.Zhou, B., Zheng, L., Wu, B., Tan, Y., Lv, O., Yi, K., ... &amp; Hong, L. (2023). Protein engineering with lightweight graph denoising neural networks.<i>Journal of Chemical Information and Modeling.</i></p><p data-pid="4o1C4h6K">2.<a href="https://link.zhihu.com/?target=https%3A//proteingym.org/benchmarks" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">proteingym.org/benchmar</span><span class="invisible">ks</span><span class="ellipsis"></span></a></p><p class="ztext-empty-paragraph"><br/></p><p data-pid="QkgB2Oqj">运营/排版：何晨龙</p>
696154210,13871b8ea367f2712f0d8b2c08620c88,博而雅科技,https://api.zhihu.com/people/13871b8ea367f2712f0d8b2c08620c88,people,专注脑机交互应用研发,<em>人工智能</em>如此强大，靠的是什么？,article,https://api.zhihu.com/articles/696154210,实现对数据的自动分析和处理。随着计算机和<em>人工智能</em>行业的不断进步，智能家居、语音助手、辅助驾驶……渐渐融入我们的衣食住行，<em>人工智能</em>成为生活中不可或缺的一部分。 而<em>人工智能</em>领域的爆发式进步增长,1,0,0,1714977209,1714977209,<p></p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-204aac392432a2934c22522fafddab0b_b.jpg" data-caption="" data-size="normal" data-rawwidth="599" data-rawheight="463" class="origin_image zh-lightbox-thumb" width="599" data-original="https://pic4.zhimg.com/v2-204aac392432a2934c22522fafddab0b_r.jpg" data-original-token="v2-204aac392432a2934c22522fafddab0b"/></figure><p data-pid="iYCir_R5">在过去的几十年里，计算机行业经历了从最初的电子管计算机到如今的超级计算机的飞速发展。随着计算能力的提升，我们逐渐进入了大数据时代，数据量呈现出爆炸式增长。而如何有效地处理和分析这些数据，成为了摆在我们面前的一大挑战。</p><p data-pid="ydIbvKZR">人工智能技术的出现，为我们提供了一种解决方案。它可以通过模拟人类的思维过程，实现对数据的自动分析和处理。随着计算机和人工智能行业的不断进步，智能家居、语音助手、辅助驾驶……渐渐融入我们的衣食住行，人工智能成为生活中不可或缺的一部分。</p><p data-pid="CcVFsPzZ">而人工智能领域的爆发式进步增长，离不开神经网络模型这项关键技术支撑。</p><p class="ztext-empty-paragraph"><br/></p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-fddf9b09962899ec91608287814e1802_b.jpg" data-caption="" data-size="normal" data-rawwidth="501" data-rawheight="512" class="origin_image zh-lightbox-thumb" width="501" data-original="https://pic3.zhimg.com/v2-fddf9b09962899ec91608287814e1802_r.jpg" data-original-token="v2-fddf9b09962899ec91608287814e1802"/></figure><p data-pid="SiNu6qIm">神经网络模型，顾名思义，是模拟人脑神经元连接方式而构建的一种计算模型。它由大量的“神经元”（即神经网络中的节点）相互连接而成，每个神经元接收来自其他神经元的信号，并根据一定的规则进行处理后输出信号给下一层神经元。这种处理过程类似于人脑中的神经元传递信息，使得神经网络能够模拟人类的思维过程。</p><p data-pid="C6d-geWk">神经网络模型的核心在于其强大的学习和适应能力。通过训练，神经网络可以调整神经元之间的连接权重，从而优化自身的性能。这种训练过程通常涉及大量的数据输入和反复迭代，使得神经网络能够逐渐学习到数据的内在规律和模式。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-a96ffd90884bddf872193c5a4938ed48_b.jpg" data-caption="" data-size="normal" data-rawwidth="1311" data-rawheight="991" class="origin_image zh-lightbox-thumb" width="1311" data-original="https://pic1.zhimg.com/v2-a96ffd90884bddf872193c5a4938ed48_r.jpg" data-original-token="v2-a96ffd90884bddf872193c5a4938ed48"/></figure><p data-pid="7Ec9dzh2">神经网络模型的发展历史可以追溯到上世纪40年代，当时心理学家Warren McCulloch和数学家Walter Pitts提出了第一个基于生物神经元的计算模型。然而，由于计算能力的限制，神经网络的研究进展缓慢。直到20世纪80年代，随着计算机技术的突破，神经网络才重新受到关注。</p><p data-pid="fz4lb6Vp">进入21世纪，随着大数据时代的到来和计算能力的飞速提升，神经网络模型迎来了发展的黄金时期。2006年，加拿大教授Geoffrey Hinton提出了“深度学习”的概念，为神经网络的发展指明了方向。随后，卷积神经网络（CNN）、循环神经网络（RNN）等新型神经网络模型相继问世，并在图像识别、语音识别等领域取得了突破性进展。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-8675f39063233fe76a1bfeaa7554c1a4_b.jpg" data-caption="" data-size="normal" data-rawwidth="511" data-rawheight="341" class="origin_image zh-lightbox-thumb" width="511" data-original="https://pic1.zhimg.com/v2-8675f39063233fe76a1bfeaa7554c1a4_r.jpg" data-original-token="v2-8675f39063233fe76a1bfeaa7554c1a4"/></figure><p data-pid="ho80u7jI">如今，神经网络模型已经广泛应用于各个领域，成为人工智能技术的核心之一。</p><p data-pid="O6aTxNLg">在图像识别领域，神经网络模型通过训练，对图像像素的分析和处理，实现对图像的自动分类和识别出图片中的物体、场景和情感等信息，为自动驾驶、人脸识别等领域提供了强大的技术支持。</p><p data-pid="ASpl_DXW">在语音识别和自然语言处理方面，神经网络模型可以通过对语音信号的分析和处理，实现对语音的自动识别和转换，使得计算机能够理解和生成人类语言，从而实现智能客服、语音助手、机器翻译等实用功能。</p><p data-pid="EwJv3j70">此外，神经网络模型还可以帮助我们更好地理解和处理复杂庞大的数据，为决策制定提供精准的分析支持，提高我们的科研工作效率，例如在一些高精尖的专业领域发挥着重要作用，如金融分析、市场预测、医学影像分析、能源管理等。</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-2bf54d0d8e430f611d3e54dcffc32c53_b.jpg" data-caption="" data-size="normal" data-rawwidth="1200" data-rawheight="800" class="origin_image zh-lightbox-thumb" width="1200" data-original="https://pic4.zhimg.com/v2-2bf54d0d8e430f611d3e54dcffc32c53_r.jpg" data-original-token="v2-2bf54d0d8e430f611d3e54dcffc32c53"/></figure><p data-pid="gK0PcHmo">尽管神经网络模型在人工智能领域的成就已经不容小觑，但目前而言其最大价值还远远没有实现，真正“完美”的模型仍未出现，这是因为模型开发是一项具有十分高难度的挑战。</p><p data-pid="eulq_FF2">例如，模型的训练需要大量的数据和计算资源，而数据的获取和处理往往是一项艰巨的任务；并且，神经网络的“黑箱”特性使得其决策过程缺乏透明度，难以解释和信任；此外，如何保证模型的鲁棒性（强健性或抗干扰性）和泛化能力，如何避免模型的过拟合和欠拟合等问题，都需要我们进行深入研究和探索；当然，我们对人类自身神经系统的了解也有局限。</p><p data-pid="MCbWK4--">未来，随着算力提升和数据不断增加，我们希望能够逐渐解决这些挑战。</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-91602762e08a3682018d62951c9038b7_b.jpg" data-caption="" data-size="normal" data-rawwidth="1024" data-rawheight="672" class="origin_image zh-lightbox-thumb" width="1024" data-original="https://pic4.zhimg.com/v2-91602762e08a3682018d62951c9038b7_r.jpg" data-original-token="v2-91602762e08a3682018d62951c9038b7"/></figure><p data-pid="avMt8t5y">首先，我们可以训练更加复杂、更加精准的神经网络模型，以便大大提升模型的准确性和效率；其次，新型的神经网络架构和算法将进一步提高模型的效率和性能，降低对数据和计算资源的需求；第三，可解释性人工智能（XAI）的研究将帮助我们理解神经网络的决策过程，增强人们对AI技术的信任和接受度；与其他技术相结合，形成更加智能化的系统，例如，与物联网相结合，实现对各种设备的智能控制和管理，与区块链技术相结合，实现更加安全、可靠的数据处理和交换。</p><p data-pid="ROkWRl3F">总之，随着计算机和人工智能行业的不断发展，神经网络模型还将会有诸多突破和变革，我们期待着未来神经网络模型能够为我们带来更多的惊喜和改变。</p>
696128356,dbbf3e5ecc8e6ee364e14ef026f36769,felonwan,https://api.zhihu.com/people/dbbf3e5ecc8e6ee364e14ef026f36769,people,,[译]<em>人工智能</em>比以往任何时候都更需要神经科学,article,https://api.zhihu.com/articles/696128356,大脑不仅使用大型<em>人工智能</em>模型所用能量的一小部分，而且它也是“真正”智能的。与<em>人工智能</em>系统不同，大脑可以理解其环境的结构，从而做出复杂的预测并执行智能的行动。与人工智能模型不同,6,0,7,1714968956,1714973861,<p data-pid="I0nSORUL">来源：<a href="https://link.zhihu.com/?target=https%3A//www.numenta.com/blog/2023/08/15/ai-needs-neuroscience-more-than-ever/" class=" wrap external" target="_blank" rel="nofollow noreferrer">AI Needs Neuroscience More than Ever</a>，为Numenta公司官方Blog。</p><p data-pid="_10Q2Ndt">发表时间：2023年8月15日</p><p data-pid="kbRVpTsC">本次编译过程中采用谷歌翻译。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-c083c1447340c4c7e421dc1e7085394a_b.jpg" data-caption="" data-size="normal" data-rawwidth="1440" data-rawheight="785" class="origin_image zh-lightbox-thumb" width="1440" data-original="https://pic3.zhimg.com/v2-c083c1447340c4c7e421dc1e7085394a_r.jpg" data-original-token="v2-f0ab47eee8fcc8607592720ca61390f1"/></figure><p data-pid="2zyKditJ"><b><i>本文最初发表于<a href="https://link.zhihu.com/?target=https%3A//fortune.com/2023/08/15/today-cutting-edge-artificial-intelligence-based-neuroscience-50s-60s-imagine-ai-could-do-incorporate-latest-breakthroughs-tech/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Fortune.com</a>。 </i></b> </p><p data-pid="Yt6VypXF">随着围绕 ChatGPT 的大肆宣传，大多数人都对人工智能的前景感到兴奋，但他们却忽视了它的陷阱。如果我们想要拥有真正的智能机器，<b>能够理解其环境、持续学习并每天为我们提供帮助</b>，我们需要将神经科学应用于深度学习人工智能模型。然而，除了少数例外，这两个学科几十年来一直令人惊讶地处于孤立状态。</p><p data-pid="aFPMn19U">情况并非总是如此。20 世纪 30 年代，<a href="https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Donald_O._Hebb" class=" wrap external" target="_blank" rel="nofollow noreferrer">唐纳德·赫布 (Donald Hebb</a>  ) 等人提出了神经元如何学习的理论，启发了第一个深度学习模型。随后在 20 世纪 50 年代和 60 年代，  <a href="https://link.zhihu.com/?target=https%3A//braintour.harvard.edu/archives/portfolio-items/hubel-and-wiesel" class=" wrap external" target="_blank" rel="nofollow noreferrer">David Hubel 和 Torsten Wiesel</a>因了解大脑感知系统的工作原理而获得了诺贝尔奖。这对<a href="https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Convolutional_neural_network" class=" wrap external" target="_blank" rel="nofollow noreferrer">卷积神经网络</a>产生了重大影响，而卷积神经网络是当今人工智能深度学习的重要组成部分。</p><h2>大脑的超能力</h2><p data-pid="GXMV4iXh">虽然神经科学作为一个领域在过去 20 到 30 年里取得了爆炸性的发展，但这些最近的突破在当今的人工智能系统中几乎没有一个是显而易见的。如果你问今天的普通人工智能专业人士，他们不知道这些进步，也不明白最近的神经科学突破会对人工智能产生什么影响。如果我们希望人工智能系统能够突破科学和知识的界限，那么就必须改变这一点。</p><p data-pid="YxVESACF">例如，我们现在知道，<a href="https://link.zhihu.com/?target=https%3A//www.nature.com/articles/s41583-022-00658-6" class=" wrap external" target="_blank" rel="nofollow noreferrer">我们的大脑中有一个通用电路</a>，它可以用作人工智能的模板。</p><p data-pid="mVaKHdtk">对于一个普通成年人来说，人脑消耗的功率约为 20 瓦，不到一个灯泡消耗功率的一半。一月份，ChatGPT 消耗的 <a href="https://link.zhihu.com/?target=https%3A//towardsdatascience.com/chatgpts-electricity-consumption-7873483feac4%23%3A~%3Atext%3DTraining%2520ChatGPT%2527s%2520underlying%2520language%2520model%2Cthe%2520same%2520amount%2520of%2520energy." class=" wrap external" target="_blank" rel="nofollow noreferrer">电量大约相当于 175,000 人</a>。鉴于 <a href="https://link.zhihu.com/?target=https%3A//johnnosta.medium.com/the-most-important-chart-in-100-years-1095915e1605" class=" wrap external" target="_blank" rel="nofollow noreferrer">ChatGPT 的使用率迅速上升</a>，目前它每月消耗的电力相当于 1,000,000 人。马萨诸塞大学阿默斯特分校的一篇 <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1906.02243" class=" wrap external" target="_blank" rel="nofollow noreferrer">论文</a> 指出，“训练一个人工智能模型，其一生所排放的碳相当于五辆汽车的碳排放量。”然而，这一分析仅涉及 <i>一次</i> 训练。当模型通过反复训练得到改进时，能量消耗会大大增加。</p><p data-pid="FOzGnoty">除了能源消耗之外，自 2012 年以来，训练这些人工智能系统所需的计算资源 <a href="https://link.zhihu.com/?target=https%3A//openai.com/blog/ai-and-compute/" class=" wrap external" target="_blank" rel="nofollow noreferrer">每 3.4 个月就会翻一番</a> 。如今，随着人工智能使用量的惊人增长，估计推理成本（和电力使用）至少增加了 10 倍高于培训费用。这是完全不可持续的。</p><p data-pid="A_TPLDgh">大脑不仅使用大型人工智能模型所用能量的一小部分，而且它也是“真正”智能的。与人工智能系统不同，大脑可以理解其环境的结构，从而做出复杂的预测并执行智能的行动。与人工智能模型不同，<b>人类持续地、渐进地学习</b>。相反，代码还没有真正“学习”。如果人工智能模型今天犯了错误，那么它将继续重复该错误，直到使用新数据进行重新训练。</p><h2>神经科学如何提升（turbocharge）人工智能性能</h2><p data-pid="0Mp8Tjv3">尽管跨学科合作的需求不断增加，但神经科学家和人工智能从业者之间的文化差异使得沟通变得困难。在神经科学中，实验需要大量细节，每项发现都可能需要两到三年的艰苦记录、测量和分析。当研究论文发表时，其中的细节对于人工智能专业人士和计算机科学家来说往往像是官样文章。</p><p data-pid="qamGIxis">我们如何才能弥合这一差距？首先，神经科学家需要退后一步，从大局的角度解释他们的概念，这样他们的发现对人工智能专业人士来说才有意义。其次，我们需要更多具有 <a href="https://link.zhihu.com/?target=https%3A//news.stanford.edu/2019/03/18/stanford_university_launches_human-centered_ai/" class=" wrap external" target="_blank" rel="nofollow noreferrer">人工智能和神经科学混合角色</a>的研究人员 来帮助填补这两个领域之间的空白。通过跨学科合作，人工智能研究人员可以更好地了解如何将神经科学研究成果转化为<b>受大脑启发的人工智能</b>。</p><p data-pid="S87nVkFc">最近的突破证明，将基于大脑的原理应用于大型语言模型，可以将效率和可持续性提高几个数量级。在实践中，这意味着，将基于神经科学的逻辑映射到运行人工智能模型的算法、数据结构和架构，以便它可以像我们的大脑一样，在很少的训练数据上快速学习。</p><p data-pid="Q42_7nkz">一些组织正在将基于大脑的原理应用于人工智能方面取得进展，包括 <a href="https://link.zhihu.com/?target=https%3A//www.nature.com/articles/s41467-023-37180-x" class=" wrap external" target="_blank" rel="nofollow noreferrer">政府机构</a>、 <a href="https://link.zhihu.com/?target=https%3A//www.cell.com/neuron/fulltext/S0896-6273%2817%2930509-3%3F_returnURL%3Dhttps%253A%252F%252Flinkinghub.elsevier.com%252Fretrieve%252Fpii%252FS0896627317305093%253Fshowall%253Dtrue" class=" wrap external" target="_blank" rel="nofollow noreferrer">学术研究人员</a>、 <a href="https://link.zhihu.com/?target=https%3A//www.intel.com/content/www/us/en/research/neuromorphic-computing.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">英特尔</a>、  <a href="https://link.zhihu.com/?target=https%3A//www.deepmind.com/research" class=" wrap external" target="_blank" rel="nofollow noreferrer">Google DeepMind</a>以及像 <a href="https://link.zhihu.com/?target=https%3A//www.cortical.io/science/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Cortical.io</a>这样的小公司 （Cortical 使用 Numenta 的技术，并且作为我们许可协议的一部分，Numenta 拥有 Cortical 的一些技术）。如果我们想要在扩大人工智能工作的同时保护气候，因为当今的深度学习系统正在向越来越大的模型发展，那么这项工作就至关重要。</p><p data-pid="F4HpssHu">从天花疫苗到灯泡，人类所有最伟大的突破几乎都来自多重贡献和<a href="https://link.zhihu.com/?target=https%3A//news.cornell.edu/stories/2021/09/author-worlds-greatest-ideas-came-interdisciplinary-teamwork" class=" wrap external" target="_blank" rel="nofollow noreferrer">跨学科合作</a>。人工智能和神经科学也必须如此。</p><p data-pid="Ae3kbTcO">我们需要一个人工智能系统能够真正与科学家互动的未来，帮助他们创建和运行突破人类知识边界的实验。我们需要真正增强人类能力的人工智能系统，与我们所有人一起学习并在生活的各个方面为我们提供帮助。</p><p data-pid="43yPQ0UB">无论我们喜欢与否，人工智能就在这里。我们必须通过弥合神经科学与人工智能之间的差距，使其可持续且高效。只有这样，我们才能将正确的跨学科研究和商业化、教育、政策和实践应用于人工智能，从而改善人类状况。</p>
696081652,903168729a56c8d69432f493e90e1437,北京科协,https://api.zhihu.com/people/903168729a56c8d69432f493e90e1437,people,,加快发展<em>人工智能</em> 实现生产力跃升,article,https://api.zhihu.com/articles/696081652,是推动我国科技跨越发展、产业优化升级、生产力整体跃升的重要战略资源。随着<em>人工智能</em>（<em>AI</em>）技术的发展，以AI推动生产力整体跃升、加快形成新质生产力的路径越发明晰。疏通当前AI产业发展存在的堵点，对于加快发展新质生产力、推动我国经济社会高质量发展具有重要意义,0,0,0,1714958082,1714958083,<figure data-size="normal"><img src="https://pic1.zhimg.com/v2-63def75cb444eb386ea1836f720bf5b4_b.jpg" data-caption="" data-size="normal" data-rawwidth="400" data-rawheight="265" class="content_image" width="400" data-original-token="v2-63def75cb444eb386ea1836f720bf5b4"/></figure><p data-pid="bCWnbCCc"><b>习近平总书记指出，加快发展新一代人工智能是我们赢得全球科技竞争主动权的重要战略抓手，是推动我国科技跨越发展、产业优化升级、生产力整体跃升的重要战略资源。</b>随着人工智能（AI）技术的发展，以AI推动生产力整体跃升、加快形成新质生产力的路径越发明晰。疏通当前AI产业发展存在的堵点，对于加快发展新质生产力、推动我国经济社会高质量发展具有重要意义。</p><p data-pid="QxcJTbld"><b>发展新质生产力的重要引擎</b></p><p data-pid="TjH83-Dm">新质生产力是由技术革命性突破、生产要素创新性配置、产业深度转型升级而催生的当代先进生产力，它以劳动者、劳动资料、劳动对象及其优化组合的质变为基本内涵，以全要素生产率提升为核心标志。AI对上述各个维度均存在积极推动作用，是发展新质生产力的重要引擎。<b>首先，</b>在技术突破方面，通过大数据、深度学习、自然语言处理、神经网络等技术手段，AI已发展至由数十亿到数千亿个参数组成的大模型阶段，使机器具备了模仿人类思维的能力，驱动机器不仅对重复性劳动而且对创新性劳动实现了逐步替代，带来了技术的革命性突破。<b>其次，</b>在要素配置方面，AI作为新生产工具正融入社会生产各环节，它以数据作为新生产要素、算力作为新基础能源，通过人机协同新模式，以“劳动者高技能化、劳动资料智能化、劳动对象多形态化”促进了劳动者、劳动资料、劳动对象及其优化组合的质变，推动了生产要素创新性配置和全要素生产率大幅提升。<b>最后，</b>在产业升级方面，AI通过生产要素的组合优化与整体跃升，延展了传统生产边界、开拓了新型产业空间，培育了基于AI的新产业、新业态、新模式，促进了产业跨界融合与深度转型升级，并由此加快推动了新质生产力大发展。近年来，随着我国AI产业发展进入“深水区”，AI产业发展中的堵点影响新质生产力发展，主要包括以下方面。<b>一是部分AI先发技术仍处于追跑阶段。</b>当前我国AI大模型在整体架构、模型规模、数据吞吐、训练算法等核心技术方面相较于国际最高水平仍有距离。<b>二是对AI应用研发的算力供给有所不足。</b>算力是AI三个核心要素之一，我国算力存在“智算中心少、大型数据中心少、国产自主高性能算力硬件设备少”的情况。<b>三是对AI产业发展的要素支撑相对有限。</b>当前我国在AI领军人才数量上仅占全球14%，行业投资数量和投资额相对较低。</p><p data-pid="nbipMKu5"><b>多措并举疏通产业堵点</b></p><p data-pid="RyVi6zAg">针对上述AI产业堵点，应从研发体系、技术攻关、应用场景、要素保障等方面发力，使AI更好地赋能新质生产力发展。<b>一是构建AI产业研发体系，蓄足新质生产力“源头活水”。</b>要形成由“高水平研究型大学—国家级创新平台—科技领军企业—新型研发机构”构成的“顶天立地”研发体系。高水平研究型大学面向AI的基础研究、学科建设和人才培养持续深耕。国家级创新平台重点突破AI大模型的架构、规模、算法等关键核心技术。科技领军企业整合集聚创新资源，开展AI产业共性关键技术研发和产业化。新型研发机构发挥体制机制创新优势，结合AI产业需求开展目标导向的有组织科研，打通成果转化“最后一公里”。四者之间基于新型举国体制，在产学研深度融合中彼此渗透，蓄足新质生产力发展的“源头活水”。<b>二是实现AI技术突破，催生新质生产力核心动能。</b>一方面，应发挥新型举国体制优势，加大对于AI大模型底座等技术主战场以及算力软硬件等核心支撑技术的持续投入，对算力硬件设备领域的企业实施税收优惠政策，加强对CHIPLET、存算一体等关键技术的专项攻关。另一方面，应结合全国一体化算力网建设，统筹布局超算中心、智算中心、数据中心等算力基础设施建设，推动对百万核心以上规模算力资源调度能力的技术攻关，形成高效率、低成本、规模化的AI公共服务支撑平台，催生新质生产力发展的核心动能。<b>三是打造AI产业应用场景，提供新质生产力物质资料。</b>就目前情况来看，我国在通用AI领域尚未形成显著优势，而基于国内广阔市场和海量数据，可优先发力专用AI，形成“AI+行业应用”的垂直效益。深度挖掘、积极打造可应用新一代AI技术的各类场景，进一步在金融、商务、政务、教育、文旅等不同行业领域拓展场景应用，形成AI多领域跨界应用生态，推动既有行业提质降本增效和新经济增长点探索培育，提供新质生产力发展的物质资料。<b>四是强化AI产业支撑合力，巩固新质生产力要素保障。</b>应推动研究制定“AI+”行动方案或相应政策，鼓励高校、科研院所与企业共同开展AI人才培养项目，健全完善人才激励机制，充分发挥国有金融机构的信贷支持作用，鼓励政府产投基金为AI企业提供多元股权融资，完善科技保险风险共担机制。总之，要通过疏通AI产业堵点，以新一代AI技术赋能千行百业，实现经济社会各领域各环节智能化转型升级，为新质生产力发展点燃新引擎。</p><p data-pid="c2oo5xDj">来源：《科技日报》<br/></p><p data-pid="WQwqZ0nt">作者：黄卓（北京大学国家发展研究院副院长）</p><p data-pid="B0qtR4N3">周鼎（北京大学长沙计算与数字经济研究院智库中心主任助理）</p>
694580674,aedc64baed83dd8ecebc1f703487b577,xexz,https://api.zhihu.com/people/aedc64baed83dd8ecebc1f703487b577,people,,<em>人工智能</em>,article,https://api.zhihu.com/articles/694580674,这片RAM的数据线接ROM的地址线，这就是计算机。（控制表） 如果是两片RAM这样接，这就是‘<em>人工智能</em>’:-)。（反馈表）,0,0,0,1714053913,1714053913,<p data-pid="MOve90CN">一片ROM的数据线接另一片RAM的地址线，这片RAM的数据线接ROM的地址线，这就是计算机。（控制表）</p><p data-pid="zIUHxiZC">如果是两片RAM这样接，这就是‘人工智能’:-)。（反馈表）</p>
666037172,cc4430d7cd6879a36da45b4d2b24656e,思宁,https://api.zhihu.com/people/cc4430d7cd6879a36da45b4d2b24656e,people,好看的皮囊千篇一律，有趣的灵魂万里挑一,<em>人工智能</em>,article,https://api.zhihu.com/articles/666037172,近年来，有不法分子开始利用 <em>AI</em> 技术进行牟利，例如利用&#34;AI换脸&#34;冒充熟人诈骗，制作发布假新闻混淆视听、赚取流量等。此外&#34;<em>AI</em>换脸&#34;&#34;AI换声&#34;还存在法律风险，容易造成肖像权、隐私权、著作权、声音权的侵犯,1,0,1,1712983021,1712983021,<p data-pid="WICD0WC2">随着技术的迭代升级，人工智能迎来了跨越式发展，AI技术除了用于短视频创作等娱乐性的软件外，也被广泛应用于医疗、新闻传播、生物多样性监测等领域，虽然AI技术让我们的生活更加丰富，但不分人群、不设限制的运用，必然会产生一系列的问题。近年来，有不法分子开始利用 AI 技术进行牟利，例如利用&#34;AI换脸&#34;冒充熟人诈骗，制作发布假新闻混淆视听、赚取流量等。此外&#34;AI换脸&#34;&#34;AI换声&#34;还存在法律风险，容易造成肖像权、隐私权、著作权、声音权的侵犯。因此&#34;AI 应用&#34;需要多方约束规范，在源头端进一步加强公民个人信息保护，在技术端进一步普及数字水印鉴伪等技术的利用；除了法律法规的完善和监管的发力，也期待头部互联网平台能提高社会责任感，让未来的人工智能更加健康规范。</p>
690774979,868f5b2f824ce68147ee67ded3f9d47a,<em>Ai</em>翻唱-桥安,https://api.zhihu.com/people/868f5b2f824ce68147ee67ded3f9d47a,people,,探索<em>人工智能</em>的奥秘,article,https://api.zhihu.com/articles/690774979,自我修正。 <em>人工智能</em>的分类 人工智能可以分为两大类：窄AI（Narrow AI）和通用AI（General AI）。 窄AI 窄AI，也称为弱AI，是指设计用来执行特定任务的智能系统,1,0,2,1712247806,1712247806,<p data-pid="0DFgeTOo">在21世纪的科技浪潮中，人工智能（AI）已经成为一个不可忽视的力量。从智能手机到自动驾驶汽车，从虚拟助手到医疗诊断，AI的应用无处不在，极大地改变了我们的生活和工作方式。本文将为您揭开人工智能的神秘面纱，带您一探究竟。</p><p data-pid="WHizDr34"> 什么是人工智能？</p><p class="ztext-empty-paragraph"><br/></p><p data-pid="fMrim8vS">人工智能，简称AI，是指由人造系统所表现出来的智能。它是计算机科学的一个分支，旨在创建能够执行需要人类智能的任务的机器和软件。这些任务包括但不限于学习（获取信息并根据信息对其进行规则化以达到结论）、推理（使用规则达到近似或确定的结论）和自我修正。</p><p data-pid="PcgPLNm-">人工智能的分类</p><p data-pid="u3Tmm3-W">人工智能可以分为两大类：窄AI（Narrow AI）和通用AI（General AI）。</p><p data-pid="KeKZcDEZ">窄AI</p><p data-pid="t8Mr4z_A">窄AI，也称为弱AI，是指设计用来执行特定任务的智能系统。比如语音识别、图像识别、推荐系统等。这些系统在其专门的领域表现出色，但它们并不具备超出预设任务范围的智能。</p><p data-pid="OCgnAKLj">通用AI</p><p data-pid="5IFyGUJT">通用AI，也称为强AI，是指具有广泛的认知能力，能够在多种任务和环境中表现出与人类相似智能的系统。目前，强AI仍然是科学研究中的一个目标，尚未实现。</p><p data-pid="4NqhW6qP">人工智能的工作原理</p><p data-pid="9NuGCfYd">人工智能系统通常通过机器学习（Machine Learning）来获得智能。机器学习是一种数据分析方法，它使计算机系统能够通过经验自动改进性能。其中，深度学习（Deep Learning）是机器学习的一个子领域，它使用类似于人脑神经网络的结构来学习复杂的模式。</p><p data-pid="gLjweuVq">人工智能的应用</p><p data-pid="rTX40gm0">人工智能已经渗透到我们生活的方方面面：</p><p data-pid="9B214Urf">- 医疗领域：AI可以辅助医生进行疾病诊断、个性化治疗计划制定等。</p><p data-pid="0Fd-IUSk">- 金融服务：在金融领域，AI用于风险管理、交易、个人理财助手等。</p><p data-pid="zMn7jssl">- 自动驾驶：AI技术是自动驾驶汽车的核心技术之一，它使汽车能够感知周围环境并做出决策。</p><p data-pid="mV0F4kuS">- 智能家居：AI让家居设备更加智能化，如智能音箱、智能照明系统等。</p><p data-pid="Z7ag9f8D">- 娱乐产业：AI在游戏设计、电影特效制作等领域发挥着重要作用。</p><p data-pid="-O-daKvZ">人工智能的挑战与未来</p><p data-pid="Bzt1gb1h">尽管人工智能带来了许多便利，但它也面临着一些挑战，如隐私保护、道德伦理、就业影响等。未来，我们需要在发展AI技术的同时，确保其可持续、安全和负责任地使用。</p><p data-pid="cD6Cy5Zf">随着技术的不断进步，人工智能的未来充满了无限可能。我们期待着AI能够在更多领域发挥作用，为人类社会带来更多的福祉和进步。</p><p></p><p></p>
688809452,dd20e924e9c60af44628a517c5e13c9e,顽强的豆芽菜,https://api.zhihu.com/people/dd20e924e9c60af44628a517c5e13c9e,people,有话直说,<em>人工智能</em>：塑造未来的科技巨浪,article,https://api.zhihu.com/articles/688809452,我们需要认真对待<em>人工智能</em>的潜在风险，并采取有效的应对策略来确保<em>人工智能</em>技术的健康发展。 六、人工智能发展的政策建议 6.1 加强<em>人工智能</em>的监管与立法 随着人工智能技术的快速发展,0,0,0,1711326663,1711326663,<p></p><h2><b>一、人工智能的概述</b></h2><h2><b>1.1 定义与背景</b></h2><p data-pid="ujJ6Dllr">人工智能，作为21世纪最具革命性的科技浪潮，正以前所未有的速度改变着我们的世界。它涵盖了机器学习、深度学习、自然语言处理等多个技术领域，旨在模拟、延伸和扩展人的智能，实现机器能够像人类一样进行思考和决策。随着计算机技术的飞速发展，人工智能已经从最初的简单算法发展到如今的复杂系统，成为推动社会进步的重要力量。</p><p data-pid="DEIhPGKX">回顾人工智能的发展历程，我们可以清晰地看到其背后的技术积淀和不断突破。从早期的逻辑推理程序，到后来的专家系统，再到现在的深度学习，人工智能的技术基础日益坚实。同时，随着大数据、云计算等技术的普及，人工智能的应用场景也越来越广泛，从自动驾驶到医疗健康，从金融科技到智能家居，人工智能正在逐步渗透到我们生活的方方面面。</p><p data-pid="nHtZT63r">然而，人工智能的快速发展也带来了一系列挑战和机遇。一方面，数据安全与隐私保护成为亟待解决的问题。随着人工智能技术的广泛应用，个人信息的泄露和滥用风险也在不断增加。另一方面，人工智能的伦理问题也日益凸显。例如，自动驾驶汽车在面临紧急情况时应该如何选择？这是一个需要我们深入思考和探讨的问题。</p><p data-pid="--6lH0J1">尽管如此，人工智能的发展仍然充满了无限的可能性和机遇。它不仅可以提高生产效率、改善生活质量，还可以推动产业升级、创造新的就业机会。正如著名科学家霍金所说：“人工智能的发展将改变我们的生活方式和工作方式，甚至可能改变我们的思维方式。”因此，我们应该积极拥抱人工智能这一科技巨浪，共同探索其未来的无限可能。</p><h2><b>1.2 发展历程与现状</b></h2><p data-pid="GZgQWrUz">人工智能的发展历程可谓波澜壮阔，从早期的逻辑推理程序到如今的深度学习，其技术不断突破，应用领域日益广泛。在过去的几十年里，人工智能经历了从符号主义到连接主义的转变，再到如今的数据驱动阶段。随着计算能力的提升和大数据的涌现，人工智能得以快速发展，并在许多领域取得了显著成果。</p><p data-pid="JzCEK32a">以自动驾驶为例，近年来，随着深度学习技术的发展，自动驾驶技术取得了重大突破。特斯拉等公司的自动驾驶汽车已经在部分道路上实现了商业化运营，极大地提高了交通效率和安全性。此外，在医疗健康领域，人工智能也在辅助诊断、药物研发等方面发挥着越来越重要的作用。例如，IBM的Watson肿瘤助手已经能够帮助医生分析病理切片，提高诊断准确率。</p><p data-pid="XpSaiec7">然而，人工智能的发展也面临着诸多挑战。随着技术的不断进步，人工智能的伦理问题日益凸显。例如，在自动驾驶汽车面临紧急情况时，如何做出合理的决策成为了一个亟待解决的问题。此外，数据安全与隐私保护也是人工智能发展中不可忽视的问题。随着人工智能技术的广泛应用，个人数据的收集和处理成为了一个重要环节，如何保障个人数据的安全和隐私成为了一个亟待解决的问题。</p><p data-pid="uTZy6OzQ">展望未来，人工智能的发展将更加迅速和广泛。随着技术的不断创新和突破，人工智能将在更多领域发挥重要作用。同时，随着人工智能与人类社会的深度融合，我们也需要更加关注其带来的挑战和风险。正如著名科学家霍金所说：“人工智能的全面发展将带来人类的终结。”因此，我们需要在推动人工智能发展的同时，加强对其的监管和立法，确保其健康、可持续地发展。</p><h2><b>二、人工智能的技术基础</b></h2><h2><b>2.1 机器学习</b></h2><p data-pid="sjSAKFHP">机器学习作为人工智能的核心技术之一，近年来取得了显著的进展。它基于统计学和计算机科学的交叉学科，通过训练大量的数据，让计算机能够自动学习和改进，从而实现对新数据的预测和决策。机器学习在各个领域都有广泛的应用，如自动驾驶、医疗健康、金融科技等。</p><p data-pid="fnpVdusP">以自动驾驶为例，机器学习在自动驾驶车辆中发挥着至关重要的作用。通过训练大量的道路数据和交通场景，自动驾驶车辆可以识别行人、车辆、交通信号等，并自主决策行驶路线和速度。据相关数据显示，使用机器学习技术的自动驾驶车辆已经实现了在特定场景下的完全自动驾驶，大大提高了道路安全和交通效率。</p><p data-pid="LTmk2hen">机器学习还在医疗健康领域发挥着重要作用。例如，通过训练大量的医疗图像数据，机器学习可以帮助医生快速准确地识别病变部位和病情，提高诊断的准确性和效率。此外，机器学习还可以帮助医生制定个性化的治疗方案，提高治疗效果和患者的生活质量。</p><p data-pid="5pidlI7Q">然而，机器学习也面临着一些挑战和问题。其中，数据的质量和标注问题是机器学习的重要瓶颈之一。如果数据存在噪声或标注不准确，将会严重影响机器学习模型的训练效果和性能。此外，机器学习模型的泛化能力也是一个重要的问题，即模型能否在未见过的数据上进行准确的预测和决策。</p><p data-pid="_3LbpLbR">为了解决这些问题，研究者们提出了许多方法和技术。例如，数据增强技术可以通过对原始数据进行变换和扩展，增加数据的多样性和数量，从而提高模型的泛化能力。此外，迁移学习技术也可以利用已有的知识和模型，加速新模型的训练和提高性能。这些技术的发展将进一步推动机器学习在各个领域的应用和发展。</p><p data-pid="yRonVoYS">总之，机器学习作为人工智能的核心技术之一，正在深刻地改变着我们的生活和工作方式。未来，随着技术的不断创新和突破，机器学习将在更多领域发挥重要作用，为人类社会的发展和进步做出更大的贡献。</p><h2><b>2.2 深度学习</b></h2><p data-pid="7j0QfVvd">深度学习作为人工智能领域的重要分支，近年来取得了显著的进展。它基于神经网络模型，通过模拟人脑神经元的连接方式，构建出复杂的网络结构，从而实现对大量数据的高效处理和分析。深度学习的应用广泛，不仅在图像识别、语音识别等领域取得了突破，还在自然语言处理、推荐系统等方面发挥着重要作用。</p><p data-pid="RAa_SDvO">以图像识别为例，深度学习通过训练大量的图像数据，使神经网络能够自动提取图像中的特征，进而实现对图像的分类、识别等任务。据相关数据显示，深度学习在图像识别领域的准确率已经达到了惊人的水平，甚至超过了人类的识别能力。这一突破性的进展，不仅为图像识别领域带来了巨大的变革，也为其他领域的发展提供了新的思路和方法。</p><p data-pid="_4P_rpog">深度学习的发展离不开大数据的支持。随着数据量的不断增长，深度学习模型的训练效果也得到了显著提升。同时，计算机硬件的快速发展也为深度学习的训练提供了强大的计算能力。这些因素共同推动了深度学习在各个领域的应用和发展。</p><p data-pid="PN6RMCm5">然而，深度学习也面临着一些挑战和问题。例如，深度学习模型的训练需要大量的数据和计算资源，这使得其在实际应用中受到了一定的限制。此外，深度学习模型的可解释性较差，难以解释模型内部的运行机制和决策过程。这些问题需要我们在未来的研究中加以解决和完善。</p><p data-pid="kAAajnv2">总之，深度学习作为人工智能领域的重要分支，已经在多个领域取得了显著的进展。它的发展不仅推动了人工智能技术的进步，也为各个领域的创新和发展提供了新的思路和方法。未来，随着技术的不断发展和完善，深度学习将会在更多领域发挥重要作用，为人类社会的发展带来更多的机遇和挑战。</p><h2><b>2.3 自然语言处理</b></h2><p data-pid="FAGPzoVB">自然语言处理（NLP）作为人工智能领域的一个重要分支，近年来取得了显著的进展。它旨在让计算机能够理解和处理人类语言，实现人机交互的自然和流畅。随着深度学习技术的发展，NLP在各个领域的应用越来越广泛。</p><p data-pid="1ziWfnQ8">在医疗健康领域，NLP的应用尤为突出。例如，通过NLP技术，医生可以自动分析患者的症状和病史，提高诊断的准确性和效率。据研究，使用NLP技术辅助诊断，可以将医生的诊断准确率提高10%以上。此外，NLP还可以帮助医生从大量的医学文献中快速筛选出有用的信息，为临床决策提供有力支持。</p><p data-pid="vkLxXH35">在金融领域，NLP也发挥着重要作用。例如，通过NLP技术，金融机构可以自动分析大量的金融新闻和报告，提取有用的信息来辅助投资决策。此外，NLP还可以用于智能客服和风险控制等方面，提高金融服务的效率和质量。</p><p data-pid="ytk591qy">然而，NLP技术的发展也面临着一些挑战。例如，语言的复杂性和多样性使得NLP技术的实现难度很大。此外，NLP技术的准确性和可靠性也需要不断提高。为了解决这些问题，研究者们不断探索新的算法和模型，以提高NLP技术的性能和应用范围。</p><p data-pid="Uvr89kT2">正如著名计算机科学家吴恩达所说：“自然语言处理是人工智能的皇冠上的明珠。”随着技术的不断进步和应用领域的不断拓展，NLP必将在未来发挥更加重要的作用，为人类社会的发展带来更多的机遇和挑战。</p><h2><b>三、人工智能在各领域的应用</b></h2><h2><b>3.1 自动驾驶</b></h2><p data-pid="mtQzJqTj">自动驾驶作为人工智能技术在交通领域的杰出代表，正逐渐改变我们的出行方式。随着传感器技术、计算机视觉和机器学习等关键技术的不断进步，自动驾驶汽车已经能够在特定场景下实现高度自主驾驶。例如，Waymo作为谷歌母公司Alphabet的自动驾驶项目，已经在多个城市进行了商业化运营，其自动驾驶出租车服务已经累计行驶了数百万英里，证明了自动驾驶技术的可行性和安全性。</p><p data-pid="rt7bq9zM">自动驾驶的广泛应用将带来诸多益处。首先，它能够有效减少因人为失误导致的交通事故，据统计，每年全球约有120万人因交通事故而死亡，其中许多事故是由于驾驶员的疏忽或疲劳驾驶造成的。自动驾驶汽车通过精确的传感器和算法，能够更准确地感知周围环境，做出快速而准确的决策，从而大大降低事故发生率。</p><p data-pid="CbMdglRB">此外，自动驾驶还有助于提高交通效率，减少拥堵现象。根据麦肯锡的预测，到2030年，自动驾驶汽车将减少全球交通拥堵造成的经济损失约50%。自动驾驶汽车能够实时获取道路信息和车辆数据，通过智能调度和优化行驶路线，实现更高效的交通流动。</p><p data-pid="vCM4il2h">然而，自动驾驶技术的发展也面临着一些挑战。其中，数据安全和隐私保护是亟待解决的问题。自动驾驶汽车需要收集大量的道路和车辆数据来进行训练和优化，这些数据可能包含个人隐私信息。因此，在推动自动驾驶技术发展的同时，必须加强对数据安全和隐私保护的监管，确保个人信息不被滥用。</p><p data-pid="e6iEha3L">此外，自动驾驶汽车的普及还需要解决法律和伦理问题。例如，当自动驾驶汽车面临紧急情况时，应该如何做出决策以最大程度地保护乘客和其他道路使用者的安全？这需要我们在技术发展的同时，不断完善相关法律法规和伦理准则，为自动驾驶汽车的商业化运营提供坚实的法律保障。</p><p data-pid="TlV6NliX">综上所述，自动驾驶作为人工智能技术在交通领域的杰出代表，具有巨大的潜力和价值。然而，要实现自动驾驶技术的广泛应用和商业化运营，还需要克服诸多挑战。通过加强技术研发、完善法律法规和伦理准则、加强数据安全和隐私保护等措施，我们有信心推动自动驾驶技术的健康发展，为人类创造更美好的未来。</p><h2><b>3.2 医疗健康</b></h2><p data-pid="bQuAZN6w">在医疗健康领域，人工智能的应用已经取得了显著的成果。例如，通过深度学习和大数据分析，人工智能可以辅助医生进行疾病诊断和治疗方案制定。据研究，使用人工智能辅助诊断肺癌的准确率已经超过了传统方法。此外，人工智能还可以帮助医生进行手术操作，提高手术的精确度和安全性。例如，在心脏手术中，人工智能可以通过分析心脏图像数据，为医生提供最佳的手术路径和方案，从而减少手术风险和提高手术成功率。</p><p data-pid="pf_Aea35">人工智能在医疗健康领域的应用不仅提高了医疗服务的效率和质量，还降低了医疗成本。通过自动化和智能化的方式，人工智能可以减少医疗资源的浪费和人力成本，从而为患者提供更加优质和高效的医疗服务。此外，人工智能还可以帮助医疗机构进行精细化管理和优化资源配置，提高医疗服务的整体水平和竞争力。</p><p data-pid="knXQf3ei">然而，人工智能在医疗健康领域的应用也面临着一些挑战和伦理问题。例如，数据安全和隐私保护是人工智能应用中需要重点关注的问题之一。在医疗健康领域，患者的个人信息和医疗数据是非常敏感的，必须得到充分的保护。此外，人工智能在辅助诊断和治疗过程中，也可能会出现误判和误诊的情况，需要医生和患者共同承担风险。</p><p data-pid="hsrCFdh_">因此，在医疗健康领域应用人工智能时，需要充分考虑其优势和不足，并制定相应的应对策略。同时，还需要加强人工智能的监管和立法，确保其应用符合伦理和法律要求，保障患者的权益和安全。</p><h2><b>3.3 金融科技</b></h2><p data-pid="7iZ7Qu0N">金融科技作为人工智能应用的重要领域之一，正在深刻改变着金融行业的生态和格局。随着大数据、云计算、区块链等技术的不断发展，金融科技在风险管理、客户服务、产品创新等方面展现出巨大的潜力。</p><p data-pid="IElZaxH6">在风险管理方面，人工智能技术的应用使得金融机构能够更准确地评估客户的信用状况，实现风险定价的精细化。例如，基于深度学习的信用评分模型，可以通过分析客户的消费记录、社交网络等多维度数据，为客户提供个性化的信用评估服务，有效降低了信贷风险。</p><p data-pid="F2DzAZTa">在客户服务方面，金融科技通过智能客服、智能投顾等应用，提升了客户服务的效率和质量。智能客服能够实时响应客户的咨询需求，提供24小时不间断的服务；智能投顾则能够根据客户的风险偏好和投资目标，为客户提供个性化的投资建议，帮助客户实现资产的优化配置。</p><p data-pid="z71Fz_Lx">此外，金融科技还在产品创新方面发挥着重要作用。通过运用人工智能技术，金融机构能够开发出更加符合市场需求和客户偏好的金融产品。例如，基于机器学习的量化交易模型，能够帮助投资者更准确地把握市场趋势，实现资产的增值保值。</p><p data-pid="rgHr3IYo">正如阿里巴巴集团创始人马云所说：“未来的金融将是科技驱动的金融。”金融科技的发展将不断推动金融行业的创新和变革，为经济社会发展注入新的动力。</p><h2><b>四、人工智能带来的挑战与机遇</b></h2><h2><b>4.1 数据安全与隐私保护</b></h2><p data-pid="gRcYv70g">随着人工智能技术的快速发展，数据安全与隐私保护问题日益凸显。在人工智能应用过程中，大量个人数据被收集、存储和处理，这些数据包括个人身份信息、行为习惯、健康状况等敏感信息。一旦这些数据泄露或被滥用，将对个人隐私造成严重威胁，甚至可能引发社会信任危机。</p><p data-pid="K7d_2yiD">以近年来频发的数据泄露事件为例，据统计，仅2022年全球就发生了数千起数据泄露事件，涉及数亿用户的个人信息。这些事件不仅给受害者带来了巨大的经济损失和精神压力，也严重损害了企业的声誉和信任度。因此，加强数据安全与隐私保护已成为人工智能发展不可或缺的一环。</p><p data-pid="D3fJvh3u">为了应对这一挑战，我们需要从多个层面入手。首先，政府应制定和完善相关法律法规，明确数据收集、存储和使用的规范和标准，加大对违法行为的处罚力度。同时，企业也应承担起保护用户数据的责任，加强内部管理和技术防范，确保用户数据的安全性和隐私性。</p><p data-pid="fqoFQ-yO">此外，我们还需要借助先进的技术手段来加强数据安全与隐私保护。例如，通过采用加密技术、匿名化处理、差分隐私等技术手段，可以有效保护用户数据不被泄露和滥用。同时，我们也需要加强人工智能技术的研发和应用，推动人工智能与数据安全、隐私保护等领域的深度融合，为数据安全与隐私保护提供更加全面和有效的解决方案。</p><p data-pid="KOL9FoQp">正如著名计算机科学家、图灵奖获得者约翰·霍普克罗夫特所说：“隐私是信息时代的公民权利。”在人工智能快速发展的今天，我们更需要重视数据安全与隐私保护问题，确保人工智能技术的健康发展与社会的和谐稳定。</p><h2><b>4.2 人工智能的伦理问题</b></h2><p data-pid="5rp0tDX3">人工智能的伦理问题已成为全球关注的焦点。随着技术的快速发展，人工智能在各个领域的应用越来越广泛，同时也带来了一系列伦理挑战。例如，在自动驾驶领域，当车辆面临无法避免的碰撞时，应该如何做出决策？是保护乘客的安全还是尽量减少对行人的伤害？这涉及到伦理道德的权衡和取舍。此外，人工智能在医疗领域的应用也引发了关于数据隐私和患者权益的讨论。如何确保患者的个人信息不被滥用，同时保障医疗决策的公正性和准确性，是亟待解决的问题。</p><p data-pid="T6JAC0wm">为了应对这些伦理挑战，我们需要建立完善的伦理框架和监管机制。首先，政府应制定相关法律法规，明确人工智能技术的使用范围和限制，确保技术的合规性和安全性。其次，企业和研究机构应加强自律，遵循伦理原则，确保人工智能技术的健康发展。此外，我们还需要加强公众教育和意识提升，让更多人了解人工智能的伦理问题，并参与到讨论和解决中来。</p><p data-pid="hdCrh929">总之，人工智能的伦理问题不容忽视。我们需要从多个层面出发，加强监管、自律和公众参与，共同推动人工智能技术的健康发展，为人类社会带来更大的福祉。 </p><p data-pid="XS6m9n-G">近年来，人工智能的伦理问题引发了广泛的讨论。例如，在2018年，亚马逊因其招聘人工智能系统存在性别偏见而备受争议。该系统在评估简历时，更倾向于推荐男性候选人，这引发了关于算法公平性和透明度的质疑。此外，人工智能在决策过程中可能存在的歧视和偏见问题也不容忽视。例如，某些算法可能基于历史数据做出决策，而这些数据可能包含不公平的偏见，从而导致不公平的结果。</p><p data-pid="ISdoaGkZ">为了解决这些问题，我们需要建立更加完善的伦理框架和监管机制。首先，我们需要对算法进行审查和测试，确保其公平性和透明度。其次，我们需要建立独立的监管机构，对人工智能技术的使用进行监督和评估。此外，我们还需要加强公众教育和意识提升，让更多人了解人工智能的伦理问题，并参与到讨论和解决中来。</p><p data-pid="DObfkKZo">正如著名科学家爱因斯坦所说：“科技是一种强大的工具，但使用它的人必须了解它的局限性和可能的后果。”因此，我们必须认真对待人工智能的伦理问题，加强监管和自律，确保技术的健康发展，为人类社会带来更大的福祉。</p><h2><b>4.3 人工智能带来的就业机会</b></h2><p data-pid="c4qFvOrg">随着人工智能技术的快速发展，它正逐渐渗透到各个行业，为就业市场带来了前所未有的机遇。据国际数据公司（IDC）预测，到2025年，全球人工智能相关岗位将增至2300万个，其中新增的就业机会将主要来自于人工智能技术的研发、应用和维护。这一趋势不仅为科技行业带来了大量的就业机会，同时也为传统行业提供了转型升级的路径。</p><p data-pid="cmwgvJ3G">以金融行业为例，人工智能的应用使得金融服务更加智能化、个性化。智能投顾、智能风控等新型金融业态应运而生，为金融行业带来了大量的就业机会。据毕马威发布的报告，到2025年，全球金融行业将有超过30%的工作岗位被人工智能取代，但同时也会有大量新的就业机会涌现。</p><p data-pid="IGumBuXC">此外，人工智能还催生了众多新兴职业，如数据科学家、机器学习工程师、人工智能伦理顾问等。这些职业不仅需要具备深厚的技术背景，还需要具备创新思维和跨学科知识。因此，对于有志于从事人工智能领域的年轻人来说，他们可以通过不断学习和实践，提升自己的技能水平，抓住这些新兴的就业机会。</p><p data-pid="7qidyLP1">正如著名经济学家约瑟夫·熊彼特所说：“创新是经济发展的根本动力。”人工智能作为第四次工业革命的核心技术之一，正以其强大的创新力推动着就业市场的变革。因此，我们应该积极拥抱人工智能带来的就业机遇，不断提升自身技能水平，以适应未来社会的发展需求。</p><h2><b>五、人工智能的未来展望</b></h2><h2><b>5.1 技术创新与突破</b></h2><p data-pid="8JGx6nUW">在人工智能领域，技术创新与突破是推动其持续发展的关键动力。近年来，随着深度学习、强化学习等技术的快速发展，人工智能在语音识别、图像识别、自然语言处理等领域取得了显著进展。例如，在语音识别领域，通过采用深度学习技术，语音识别的准确率得到了大幅提升，已经接近甚至超越了人类水平。这种技术创新不仅改善了用户体验，也为人工智能在智能家居、医疗等领域的应用提供了更多可能性。</p><p data-pid="XpJE0l8y">此外，人工智能在算法优化、数据处理等方面也取得了重要突破。例如，通过引入注意力机制、自注意力机制等新型算法，人工智能在处理复杂任务时的性能得到了显著提升。同时，随着大数据技术的发展，人工智能可以处理的数据量也大幅增加，从而提高了其预测和决策的准确性。这些技术创新与突破为人工智能在自动驾驶、医疗健康等领域的应用提供了坚实的技术支撑。</p><p data-pid="o4Js1zlI">然而，技术创新与突破也面临着诸多挑战。随着人工智能技术的不断发展，其所需的计算资源、数据资源等成本也在不断增加。此外，人工智能技术的可解释性、鲁棒性等问题也亟待解决。因此，未来的技术创新需要更加注重算法优化、资源利用等方面的研究，以实现更高效、更可靠的人工智能技术。</p><p data-pid="QkcG_nSq">正如著名科学家爱因斯坦所说：“想象力比知识更重要。”在人工智能领域，技术创新与突破需要充分发挥想象力和创新精神，不断探索新的技术路线和应用场景。只有这样，我们才能更好地应对未来的挑战和机遇，推动人工智能技术的持续发展和广泛应用。</p><h2><b>5.2 人工智能与人类社会的融合</b></h2><p data-pid="ZtaMuRI4">人工智能与人类社会的融合正在逐渐深化，这种融合不仅改变了我们的生活方式，也重塑了社会结构和经济形态。随着技术的不断进步，人工智能已经渗透到各个领域，从医疗、教育到交通、娱乐，无所不在。例如，在医疗领域，人工智能通过深度学习和大数据分析，可以帮助医生更准确地诊断疾病，提高治疗效率。在教育领域，人工智能可以个性化地推荐学习资源，帮助学生更高效地学习。这些应用不仅提高了人们的生活质量，也推动了社会的进步。</p><p data-pid="QM5Vu_-F">然而，人工智能与人类社会的融合也带来了一系列挑战。一方面，随着人工智能的普及，许多传统职业可能面临被取代的风险，这会导致一部分人失业。另一方面，人工智能的发展也引发了数据安全和隐私保护等问题。因此，在推动人工智能与人类社会的融合过程中，我们需要关注这些问题，并采取相应的措施来应对。</p><p data-pid="Nj6OlED1">为了促进人工智能与人类社会的和谐融合，我们需要加强人工智能的监管与立法，确保技术的发展符合社会的利益。同时，我们还需要推动人工智能的产学研合作，加快技术的创新和应用。此外，培养人工智能领域的人才队伍也是至关重要的，只有拥有足够的人才储备，才能推动人工智能技术的持续发展。</p><p data-pid="5IO9Qq_o">正如著名科学家霍金所说：“人工智能的发展要么带来人类历史上最好的事情，要么带来最坏的事情。”因此，我们需要审慎地对待人工智能的发展，既要充分利用其带来的机遇，也要积极应对其带来的挑战。只有这样，我们才能实现人工智能与人类社会的和谐融合，共同创造一个更加美好的未来。</p><h2><b>5.3 人工智能的潜在风险与应对策略</b></h2><p data-pid="ZjPnRhA5">人工智能的潜在风险不容忽视。随着技术的快速发展，我们面临着数据安全与隐私保护的严峻挑战。例如，根据一项研究，近年来因人工智能技术泄露的个人数据数量呈指数级增长。这些泄露的数据可能被用于恶意目的，如身份盗窃或欺诈行为。此外，人工智能的决策过程也可能存在偏见和歧视，这可能导致不公平的结果。例如，某些招聘算法已被发现对特定性别或种族的候选人存在偏见。因此，我们需要采取应对策略来减轻这些风险。</p><p data-pid="vSQk-H19">首先，加强数据安全和隐私保护是至关重要的。企业和政府应加大投入，研发更先进的数据加密技术和隐私保护算法，确保个人数据不被滥用。此外，建立严格的数据监管机制也是必要的，以确保数据在合法、公正、透明的环境下使用。同时，我们还需要提高公众对数据安全和隐私保护的意识，教育他们如何保护自己的个人信息。</p><p data-pid="N8t9TCfz">其次，解决人工智能决策过程中的偏见和歧视问题也是关键。这需要我们建立更加公正和透明的算法开发过程，确保算法的公平性和公正性。此外，对算法进行定期审查和更新也是必要的，以确保其适应不断变化的社会环境和需求。同时，我们还需要建立有效的监管机制，对算法的使用进行监督和评估，确保其不会对个人和社会造成不公平的影响。</p><p data-pid="sgg59V4V">正如著名科学家霍金所说：“人工智能的全面发展将带来人类历史上最大的变革。它将改变我们的生活方式，甚至改变我们是谁。但除非我们学会如何避免危险，否则我们可能无法控制它。”因此，我们需要认真对待人工智能的潜在风险，并采取有效的应对策略来确保人工智能技术的健康发展。</p><h2><b>六、人工智能发展的政策建议</b></h2><h2><b>6.1 加强人工智能的监管与立法</b></h2><p data-pid="kmeJfav3">随着人工智能技术的快速发展，其在各个领域的应用越来越广泛，但同时也带来了一系列的问题和挑战。为了保障人工智能技术的健康发展，加强人工智能的监管与立法显得尤为重要。 </p><p data-pid="ahXzETaO">首先，加强人工智能的监管可以有效避免技术滥用和误用。近年来，人工智能技术在人脸识别、智能监控等领域的应用越来越广泛，但同时也引发了一些争议。例如，一些商家滥用人工智能技术收集用户信息，侵犯用户隐私；一些政府机构过度依赖人工智能技术，导致决策失误等问题。因此，加强人工智能的监管可以有效规范技术的使用，保障公众利益。 </p><p data-pid="QXZqjTbW">其次，加强人工智能的立法可以为技术的发展提供法律保障。目前，人工智能技术在全球范围内仍处于快速发展阶段，相关的法律法规还不够完善。因此，加强人工智能的立法可以为技术的发展提供法律保障，规范各方的行为，促进技术的健康发展。 </p><p data-pid="VBmdxW81">此外，加强人工智能的监管与立法还可以促进技术的创新和发展。在监管和立法的推动下，人工智能技术将更加注重安全性和可靠性，推动技术的创新和发展。同时，加强监管和立法也可以为人工智能技术的商业化应用提供更加稳定的环境，吸引更多的投资和支持。 </p><p data-pid="1gXMYYRG">总之，加强人工智能的监管与立法是保障人工智能技术健康发展的重要措施。通过加强监管和立法，可以有效避免技术滥用和误用，为技术的发展提供法律保障，促进技术的创新和发展。同时，也需要各方共同努力，推动人工智能技术的健康发展，为人类社会的进步和发展做出更大的贡献。</p><h2><b>6.2 推动人工智能的产学研合作</b></h2><p data-pid="QsCKrUzv">推动人工智能的产学研合作对于促进人工智能技术的快速发展和应用至关重要。产学研合作能够汇聚各方资源，形成合力，共同推动人工智能技术的创新和应用。通过加强产学研合作，可以加速人工智能技术的研发进程，提高技术应用的效率和效果。</p><p data-pid="LIthoq-O">以自动驾驶为例，产学研合作在自动驾驶技术的研发和应用中发挥了重要作用。高校和研究机构在自动驾驶算法和传感器技术方面进行了深入研究，为自动驾驶技术的发展提供了理论支持。同时，企业则将这些研究成果应用于实际产品中，通过不断的试验和改进，推动了自动驾驶技术的快速发展。这种产学研合作模式不仅加速了自动驾驶技术的研发进程，还提高了技术应用的可靠性和安全性。</p><p data-pid="x0qvpiGS">此外，产学研合作还能够促进人工智能技术的广泛应用。通过合作，企业可以将高校和研究机构的研究成果转化为实际产品，满足市场需求，推动人工智能技术在各个领域的应用。例如，在医疗健康领域，产学研合作推动了人工智能在医学影像分析、疾病诊断和治疗等方面的应用，提高了医疗服务的效率和质量。</p><p data-pid="Uqncl7QG">然而，推动人工智能的产学研合作也面临一些挑战。首先，各方之间的合作需要建立在相互信任的基础上，需要加强沟通和协调。其次，产学研合作需要投入大量的人力、物力和财力，需要各方共同承担风险和成本。因此，需要建立有效的合作机制和合作模式，促进各方的积极参与和合作。</p><p data-pid="d4WUE6lv">总之，推动人工智能的产学研合作是促进人工智能技术快速发展和应用的重要途径。通过加强合作，可以汇聚各方资源，形成合力，共同推动人工智能技术的创新和应用。同时，也需要建立有效的合作机制和合作模式，促进各方的积极参与和合作，共同应对人工智能发展面临的挑战和机遇。</p><h2><b>6.3 培养人工智能领域的人才队伍</b></h2><p data-pid="28C_ePAt">在人工智能的浪潮中，培养一支高素质的人才队伍显得尤为重要。随着技术的飞速发展，人工智能领域对人才的需求日益旺盛。据预测，到2025年，全球人工智能领域的人才缺口将达到数百万。因此，加强人工智能领域的人才培养，不仅有助于推动科技进步，更是应对未来社会经济发展挑战的关键。</p><p data-pid="27ShbvVQ">为了培养高质量的人工智能人才，我们需要构建一个完善的教育体系。这包括从基础教育阶段就开始培养学生的编程思维、数据分析和创新能力。同时，高等教育机构也应设立更多的人工智能相关专业，并引入国际先进的教学资源和方法。例如，斯坦福大学、麻省理工学院等世界顶尖学府在人工智能教育方面走在前列，他们的成功经验值得我们借鉴。</p><p data-pid="gzm5FWh3">除了教育体系的建设，我们还应注重实践能力的培养。人工智能是一门高度实践性的学科，只有通过大量的项目实践，学生才能真正掌握相关技能。因此，企业和研究机构应与教育机构紧密合作，为学生提供实习和实践的机会。这种“产学研”结合的模式，既有利于学生的成长，也能推动人工智能技术的实际应用。</p><p data-pid="KzKd0BJZ">此外，我们还应关注人工智能伦理和法规的教育。随着人工智能技术的广泛应用，如何确保技术的合理、安全、可控使用成为了一个重要议题。因此，培养具备伦理意识和法规知识的人工智能人才至关重要。这要求我们在教育过程中，不仅要注重技术知识的传授，更要加强伦理和法规的教育，培养学生的社会责任感和职业道德。</p><p data-pid="Ep5BcSKS">正如著名科学家爱因斯坦所说：“教育的首要目标永远是独立思考和判断，而非特定的知识。”在人工智能领域的人才培养中，我们更应注重培养学生的创新思维和批判性思维。只有这样，我们才能培养出真正能够适应未来社会发展需要的人工智能人才。</p>
687712357,e3f398083013068e1df4f73ac086a3eb,控制工程老学长,https://api.zhihu.com/people/e3f398083013068e1df4f73ac086a3eb,people,很多文章在反复修改，一直在学习请各位批评指正！,对<em>人工智能</em>领域的一些个人看法,article,https://api.zhihu.com/articles/687712357,数据如果不准确可能导致AI做出错误的决策，因此如何获得高质量的训练数据或者如何让<em>人工智能</em>识别出数据中的问题是关键。 4. <em>人工智能</em>对社会的影响 AI正在改变劳动力市场,0,0,0,1710765851,1711267035,<p data-pid="RF7j6oaW">文章脉络：我们想了解人工智能领域，首先应该了解人工智能是怎么来的也就是它的历史背景，其次现在发展到哪了，现在的发展该存在什么问题呢？以及为什么要发展人工智能也就是对社会产生什么影响呢？未来发展的大方向是什么呢？</p><p data-pid="81gzJesA">所以本文的内容依次介绍：人工智能历史背景、发展现状、存在问题、对社会的影响、未来发展趋势。</p><h2>1. 人工智能历史背景</h2><p data-pid="bFmKXF_K">人工智能的概念最早可以追溯到20世纪中叶，其中著名事件有：AlphaGo击败了世界围棋冠军李世石、OpenAI发布了GPT大模型等。近年来，随着计算能力的提升和数据量的爆炸性增长，AI技术取得了前所未有的进展。</p><h2>2. 发展现状</h2><p data-pid="3t1J89bu">人工智能现在正处于快速发展期，我们可以看一下人工智能领域的论文数量变化曲线</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-2b23636c2f3cbe845171782be9a1d350_b.jpg" data-rawwidth="861" data-rawheight="575" data-size="normal" data-caption="" class="origin_image zh-lightbox-thumb" width="861" data-original="https://pic1.zhimg.com/v2-2b23636c2f3cbe845171782be9a1d350_r.jpg" data-original-token="v2-b3d358e0e7c11f081b88c5131dc4055a"/></figure><p data-pid="rPzrhTN1">深度学习和机器学习技术的进步推动了AI在图像识别、自然语言处理、自动驾驶等领域的突破。在大模型领域基于之前的研究成果持续扩展，例如，ChatGPT（GPT-3.5）升级到GPT-4，华为公司的盘古大模型更是已经应用到了各行各业。但是人工智能领域也存在一些核心问题。</p><h2>3. 人工智能领域要解决的问题</h2><p data-pid="4Ap9OARH">    3.1 首先就是算力的消耗，训练人工智能模型需要消耗大量的电力，所以提高算法的效率是面临的一个问题。</p><p data-pid="k00RmwiK">    3.2 其次就是高性能的GPU紧缺，随着主流深度学习算法的发展，应研发出能稳定运行这些算法的智能芯片。</p><p data-pid="u82OhkoP">    3.3  此外，AI的决策很大程度上依赖于训练的数据，数据如果不准确可能导致AI做出错误的决策，因此如何获得高质量的训练数据或者如何让人工智能识别出数据中的问题是关键。</p><h2>4. 人工智能对社会的影响</h2><p data-pid="SESO2BJL">AI正在改变劳动力市场，电话客服等一些工作岗位很可能随着AI 的发展逐渐被取代，同时AI也大大提升人类的工作效率，技术难题，重复无聊的工作交给AI都会帮你解决。但是，AI的伦理问题包括数据隐私、算法偏见（数据中如果提现了一些偏见思想，同样学习后的大模型可能也会具有甚至还可能会放大）、责任归属（AI做出的决策责任归属方，例如无人车撞到人是谁的责任）等也同样存在。所以应该制定相应地法律法规完善AI的发展。</p><h2>5. 人工智能未来发展趋势</h2><p data-pid="ECNVpWnL">5.1 AI的未来发展可能会更加智能自适应地学习和调整自己的决策，同时在资源受限的环境下使用小模型、轻量级AI，也是不可阻挡的发展趋势。</p><p data-pid="UTMOtXzx">5.2 AI与其他技术如智能医疗方面会更加普及，也会持续推进生产自动化，无人驾驶，智能物流的发展。</p>
